<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux-tree命令]]></title>
    <url>%2FLinux-tree%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[tree 概述tree命令的中文意思为“树”，功能是以树形结构列出指定目录下的所有内容，包括所有文件、子目录及子目录里的目录和文件。 安装1yum install -y tree 参数1234567891011121314151617181920-a 显示所有文件和目录。-A 使用ASNI绘图字符显示树状图而非以ASCII字符组合。-C 在文件和目录清单加上色彩，便于区分各种类型。-d 显示目录名称而非内容。-D 列出文件或目录的更改时间。-f 在每个文件或目录之前，显示完整的相对路径名称。-F 在执行文件，目录，Socket，符号连接，管道名称名称，各自加上&quot;*&quot;,&quot;/&quot;,&quot;=&quot;,&quot;@&quot;,&quot;|&quot;号。-g 列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码。-i 不以阶梯状列出文件或目录名称。-I 不显示符合范本样式的文件或目录名称。-l 如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录。-n 不在文件和目录清单加上色彩。-N 直接列出文件和目录名称，包括控制字符。-p 列出权限标示。-P 只显示符合范本样式的文件或目录名称。-q 用&quot;?&quot;号取代控制字符，列出文件和目录名称。-s 列出文件或目录大小。-t 用文件和目录的更改时间排序。-u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。-x 将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该子目录予以排除在寻找范围外。 示例12345678[root@ops-jenkins-master test]# tree k8s/k8s/└── ingress ├── Dockerfile ├── nginx.tmpl └── nginx.tmpl-bak1 directory, 3 files]]></content>
  </entry>
  <entry>
    <title><![CDATA[Helm-简化应用部署]]></title>
    <url>%2FHelm-%E7%AE%80%E5%8C%96%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[参考链接 https://help.aliyun.com/document_detail/86511.html 在 Kubernetes 中，应用管理是需求最多、挑战最大的领域。Helm 项目提供了一个统一软件打包方式，支持版本控制，可以大大简化 Kubernetes 应用分发与部署中的复杂性。 阿里云容器服务在应用目录管理功能中集成了 Helm 工具，并进行了功能扩展，支持官方 Repository，让您快速部署应用。您可以通过命令行或容器服务控制台界面两种方式进行部署。 Helm 基本概念Helm 是由 Deis 发起的一个开源工具，有助于简化部署和管理 Kubernetes 应用。 Helm 可以理解为 Kubernetes 的包管理工具，可以方便地发现、共享和使用为 Kubernetes 构建的应用，它包含几个基本概念 Chart：一个 Helm 包，其中包含了运行一个应用所需要的镜像、依赖和资源定义等，还可能包含 Kubernetes 集群中的服务定义，类似 Homebrew 中的 formula、APT 的 dpkg 或者 Yum 的 rpm 文件。 Release：在 Kubernetes 集群上运行的 Chart 的一个实例。在同一个集群上，一个 Chart 可以安装很多次。每次安装都会创建一个新的 release。例如一个 MySQL Chart，如果想在服务器上运行两个数据库，就可以把这个 Chart 安装两次。每次安装都会生成自己的 Release，会有自己的 Release 名称。 Repository：用于发布和存储 Chart 的存储库。 Helm 组件Helm 采用客户端/服务器架构，由如下组件组成： Helm CLI 是 Helm 客户端，可以在 Kubernetes 集群的 master 节点或者本地执行。 Tiller 是服务器端组件，在 Kubernetes 集群上运行，并管理 Kubernetes 应用程序的生命周期。 Repository 是 Chart 存储库，Helm 客户端通过 HTTP 协议来访问存储库中 Chart 的索引文件和压缩包。 安装配置 Helm CLI 安装和配置kubectl 安装heml https://github.com/helm/helm/releases 安装方法，参见 Install Helm。 1234567891011# 1、获取安装包wget https://get.helm.sh/helm-v2.14.2-linux-amd64.tar.gz# 2、解压tar zxf helm-v2.14.2-linux-amd64.tar.gz# 3、Find the helm binary in the unpacked directory, and move it to its desired destinationmv linux-amd64/helm /usr/local/bin/helm# 4、验证helm help 配置 Helm 的 Repository。这里我们使用了阿里云容器服务提供的 Charts 存储库。 123helm init --client-only --stable-repo-url https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts/helm repo add incubator https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts-incubator/helm repo update Helm基础操作 若要查看在集群上安装的 Charts 列表，请键入： 1helm list 或者缩写 1helm ls 若要查看存储库配置，请键入： 1helm repo list 若要查看或搜索存储库中的 Helm charts，请键入以下任一命令： 123helm search helm search 存储库名称 #如 stable 或 incubatorhelm search chart名称 #如 wordpress 或 spark 若要更新 charts 列表以获取最新版本，请键入： 1helm repo update 删除应用 1helm delete --purge &quot;myspark&quot; 有关 Helm 使用的详细信息，请参阅 Helm项目。 使用第三方的 Chart 存储库您除了可以使用预置的阿里云的 Chart 存储库，也可以使用第三方的 Chart 存储库（前提是网络是可达的）。使用如下命令格式添加第三方 Chart 存储库。 12helm repo add 存储库名 存储库URLhelm repo update 关于 Helm 相关命令的说明，您可以参阅 Helm 文档 参考信息Helm 催生了社区的发展壮大，越来越多的软件提供商，如 Bitnami 等公司，开始提供高质量的 Charts。您可以在 https://kubeapps.com/ 中寻找和发现已有的 Charts。]]></content>
  </entry>
  <entry>
    <title><![CDATA[ab-Apache_HTTP压测工具]]></title>
    <url>%2Fab-Apache-HTTP%E5%8E%8B%E6%B5%8B%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[官网：https://httpd.apache.org/docs/2.4/programs/ab.html 概述：网站性能压力测试是服务器网站性能调优过程中必不可缺少的一环。只有让服务器处在高压情况下，才能真正体现出软件、硬件等各种设置不当所暴露出的问题。 性能测试工具目前最常见的有以下几种：ab、http_load、webbench、siege。今天我们专门来介绍ab。 ab是apache自带的压力测试工具。ab非常实用，它不仅可以对apache服务器进行网站访问压力测试，也可以对或其它类型的服务器进行压力测试。比如nginx、tomcat、IIS等。 原理：ab是apachebench命令的缩写。 ab的原理：ab命令会创建多个并发访问线程，模拟多个访问者同时对某一URL地址进行访问。它的测试目标是基于URL的，因此，它既可以用来测试apache的负载压力，也可以测试nginx、lighthttp、tomcat、IIS等其它Web服务器的压力。 ab命令对发出负载的计算机要求很低，它既不会占用很高CPU，也不会占用很多内存。但却会给目标服务器造成巨大的负载，其原理类似CC攻击。自己测试使用也需要注意，否则一次上太多的负载。可能造成目标服务器资源耗完，严重时甚至导致死机。 安装：1yum -y install httpd-tools 12345[root@ops-jenkins-master ~]# ab -VThis is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/ 参数:1ab -help 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647-n 在测试会话中所执行的请求个数。默认时，仅执行一个请求。-c 一次产生的请求个数。默认是一次一个。-t 测试所进行的最大秒数。其内部隐含值是-n 50000，它可以使对服务器的测试限制在一个固定的总时间以内。默认时，没有时间限制。-p 包含了需要POST的数据的文件。-P 对一个中转代理提供BASIC认证信任。用户名和密码由一个:隔开，并以base64编码形式发送。无论服务器是否需要(即, 是否发送了401认证需求代码)，此字符串都会被发送。-T POST数据所使用的Content-type头信息。-v 设置显示信息的详细程度-4或更大值会显示头信息，3或更大值可以显示响应代码(404,200等),2或更大值可以显示警告和其他信息。-V 显示版本号并退出。-w 以HTML表的格式输出结果。默认时，它是白色背景的两列宽度的一张表。-i 执行HEAD请求，而不是GET。-x 设置&lt;table&gt;属性的字符串。-X 对请求使用代理服务器。-y 设置&lt;tr&gt;属性的字符串。-z 设置&lt;td&gt;属性的字符串。-C 对请求附加一个Cookie:行。其典型形式是name=value的一个参数对，此参数可以重复。-H 对请求附加额外的头信息。此参数的典型形式是一个有效的头信息行，其中包含了以冒号分隔的字段和值的对(如,&quot;Accept-Encoding:zip/zop;8bit&quot;)。-A 对服务器提供BASIC认证信任。用户名和密码由一个:隔开，并以base64编码形式发送。无论服务器是否需要(即,是否发送了401认证需求代码)，此字符串都会被发送。-h 显示使用方法。-d 不显示&quot;percentage served within XX [ms] table&quot;的消息(为以前的版本提供支持)。-e 产生一个以逗号分隔的(CSV)文件，其中包含了处理每个相应百分比的请求所需要(从1%到100%)的相应百分比的(以微妙为单位)时间。由于这种格式已经“二进制化”，所以比&apos;gnuplot&apos;格式更有用。-g 把所有测试结果写入一个&apos;gnuplot&apos;或者TSV(以Tab分隔的)文件。此文件可以方便地导入到Gnuplot,IDL,Mathematica,Igor甚至Excel中。其中的第一行为标题。-i 执行HEAD请求，而不是GET。-k 启用HTTP KeepAlive功能，即在一个HTTP会话中执行多个请求。默认时，不启用KeepAlive功能。-q 如果处理的请求数大于150，ab每处理大约10%或者100个请求时，会在stderr输出一个进度计数。此-q标记可以抑制这些信息。 性能指标： 吞吐率（Requests per second） 概念：服务器并发处理能力的量化描述，单位是reqs/s，指的是某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。 计算公式：总请求数 / 处理完成这些请求数所花费的时间，即Request per second = Complete requests / Time taken for tests 并发连接数（The number of concurrent connections） 概念：某个时刻服务器所接受的请求数目，简单的讲，就是一个会话。 并发用户数（The number of concurrent users，Concurrency Level） 概念：要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。 用户平均请求等待时间（Time per request） 计算公式：处理完成所有请求数所花费的时间/ （总请求数 / 并发用户数），即Time per request = Time taken for tests /（ Complete requests / Concurrency Level） 服务器平均请求等待时间（Time per request: across all concurrent requests） 计算公式：处理完成所有请求数所花费的时间 / 总请求数，即Time taken for / testsComplete requests可以看到，它是吞吐率的倒数。同时，它也=用户平均请求等待时间/并发用户数，即Time per request / Concurrency Level 示例一：123# 请求访问 https://www.zhaohongye.com/ ，访问 -n 100次，并发 -c 10次ab -c 10 -n 100 https://www.zhaohongye.com/ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 请求结果This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking www.zhaohongye.com (be patient).....doneServer Software: nginx/1.12.2 # 服务器软件Server Hostname: www.zhaohongye.com # 域名Server Port: 443 # 请求端口号SSL/TLS Protocol: TLSv1.2,ECDHE-RSA-AES256-GCM-SHA384,2048,256Document Path: / # 文件路径Document Length: 68872 bytes # 页面字节数Concurrency Level: 10 # 请求并发数Time taken for tests: 14.797 seconds # 总访问时间Complete requests: 100 # 总请求次数Failed requests: 0 # 失败请求次数Write errors: 0 Total transferred: 6901400 bytes # 请求总数据大小（包括header头信息）HTML transferred: 6887200 bytes # html页面实际总字节数Requests per second: 6.76 [#/sec] (mean) # 每秒多少请求，服务器的吞吐量Time per request: 1479.677 [ms] (mean) # 用户平均请求等待时间 Time per request: 147.968 [ms] (mean, across all concurrent requests) # 服务器平均处理时间，也就是服务器吞吐量的倒数 Transfer rate: 455.48 [Kbytes/sec] received #每秒获取的数据长度Connection Times (ms) min mean[+/-sd] median maxConnect: 5 12 3.3 12 19Processing: 156 1429 207.5 1462 1626Waiting: 155 1426 207.2 1449 1623Total: 165 1441 207.9 1476 1636Percentage of the requests served within a certain time (ms) 50% 1476 #50%用户请求在1476ms内返回 66% 1489 #60%用户请求在1489ms内返回 75% 1524 80% 1572 90% 1594 95% 1635 98% 1636 99% 1636 100% 1636 (longest request) 示例二：1ab -k -c 600 -n 100000 -p 1000.txt -T application/x-www-form-urlencoded -H "api-key:d99caed6d0997c4d3f141249c346e9d4" -H "authorization:Bearer xx" 'http://172.16.237.108/ai/search/photo/wps1' 123# 1000.txt 的内容img_url=https://goss1.vcg.com/editorial/vcg/400/new/VCG111160779787.jpg&amp;result_size=30&amp;image_type=url]]></content>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-RobotFramework执行自动化测试]]></title>
    <url>%2FJenkins-RobotFramework%E6%89%A7%E8%A1%8C%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[Jenkins-RobotFramework执行自动化测试 安装插件 添加slave节点由于master节点是linux服务器，RobotFramework软件部署在windows服务器上。 新建freestyle项目指定slave节点构建 配置通过百分比和邮件通知 构建效果]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-API]]></title>
    <url>%2FJenkins-API%2F</url>
    <content type="text"><![CDATA[Jenkins-API 需求：在自动化平台中调用jenkins API，实现程序发版、自定义任务等 实现：Python API 安装 1pip install python-jenkins examples 123456import jenkinsserver = jenkins.Jenkins('http://localhost:8080', username='myuser', password='mypassword')user = server.get_whoami()version = server.get_version()print('Hello %s from Jenkins %s' % (user['fullName'], version)) 123456789101112import jenkinsjob_name='k8s/cicd-test-0613'jenkins_server_url='http://jenkins.visualchina.com/jenkins'user_id='vcgdev'api_token='***************************'server=jenkins.Jenkins(jenkins_server_url, username=user_id, password=api_token)#String参数化构建job名为job_name的job, 参数param_dict为字典形式，如：param_dict= &#123;"param1"：“value1”， “param2”：“value2”&#125;param_dict= &#123;"Action":"程序发版","Scope":"生产环境","JenkinsApi":"true"&#125;server.build_job(job_name, parameters=param_dict)last_build_number = server.get_job_info(job_name)['lastCompletedBuild']['number']build_info = server.get_build_info(job_name, last_build_number)print(build_info) 项目截图]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-GitLab_WebHook自动构建]]></title>
    <url>%2FJenkins-GitLab-WebHook%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Jenkins-GitLab_WebHook自动构建 插件：GitLab Plugin 安装插件 开启触发器 创建只读账号 创建只读角色 分配角色给readonly账号 在GitLab代码项目中配置WebHook 测试 验证 实战下构建情况]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-邮件通知]]></title>
    <url>%2FJenkins-%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5%2F</url>
    <content type="text"><![CDATA[Jenkins-邮件通知 默认自带邮件功能 配置系统管理员邮件地址 配置邮件通知，并发送测试邮件 查收邮件 job中配置邮件通知 查看job日志 查收邮件 再将第四步中错误命令修复好，重新构建 查看job日志 查收恢复邮件 使用Email-ext插件Email-ext+plugin 安装插件可以通过系统管理→管理插件→可选插件，选择Email Extension插件进行安装： 配置发件人账号密码，smtp服务器地址，端口 配置邮件文本类型，模板内容 123456789101112131415161718&lt;hr/&gt;(本邮件是程序自动下发，请勿回复!)&lt;br/&gt;&lt;hr/&gt; Jenkins地址: $HUDSON_URL&lt;br/&gt;&lt;hr/&gt;项目名称： $PROJECT_NAME&lt;br/&gt;&lt;hr/&gt;构建编号： $BUILD_NUMBER&lt;br/&gt;&lt;hr/&gt; 构建状态： $BUILD_STATUS&lt;br/&gt;&lt;hr/&gt; 触发原因： $&#123;CAUSE&#125;&lt;br/&gt;&lt;hr/&gt; 构建日志地址： &lt;a href="$&#123;BUILD_URL&#125;console"&gt;$&#123;BUILD_URL&#125;console&lt;/a&gt;&lt;br/&gt;&lt;hr/&gt; 构建地址： &lt;a href="$BUILD_URL"&gt;$BUILD_URL&lt;/a&gt;&lt;br/&gt;&lt;hr/&gt; 变更集： $&#123;JELLY_SCRIPT,template="html"&#125;&lt;br/&gt;&lt;hr/&gt; 配置发送规则 开启邮件通知增加构建后操作步骤，选择Editable Email Notifiation 配置收件人、抄送人、是否发送附件（构建日志）等 查看job日志 查收邮件]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-域名解析+Nginx代理]]></title>
    <url>%2FJenkins-%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90-Nginx%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[配置Jenkins URL 配置域名解析 添加Nginx解析nginx配置文件如下： 123456789101112131415161718192021222324252627282930313233343536server &#123; listen 80; server_name jenkins.visualchina.com; location / &#123; rewrite ^/(.*)$ http://jenkins.visualchina.com/jenkins; &#125; location /jenkins &#123; proxy_pass http://127.0.0.1:8080/jenkins; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded_For $proxy_add_x_forwarded_for; &#125;&#125;server &#123; listen 443 ssl; server_name jenkins.visualchina.com; access_log /var/log/nginx/jenkins.visualchina.com main; error_log /var/log/nginx/jenkins.visualchina.com.error.log; ssl on; #ssl功能开启 ssl_certificate sslfile/visualchina.pem; #证书路径 ssl_certificate_key sslfile/visualchina.key; location / &#123; rewrite ^/(.*)$ http://jenkins.visualchina.com/jenkins; &#125; location /jenkins &#123; proxy_pass http://127.0.0.1:8080/jenkins; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded_For $proxy_add_x_forwarded_for; &#125;&#125;]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-用户权限管理]]></title>
    <url>%2FJenkins-%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Jenkins-用户权限管理 使用Role-based Authorization Strategy插件实现权限管理 安装插件 确认安装完成 激活基于角色的策略 自定义角色权限 分配角色给用户]]></content>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-插件管理]]></title>
    <url>%2FJenkins-%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[插件安装Web控制台安装 进入“插件管理”界面 搜索插件名称 勾选插件，选择直接安装 安装完成。（部分插件安装后需重启，勾选重启Jenkins选项即可。） 上传插件公司以前使用Swarm管理Docker容器，用到aliyun-container-service-deploy的jenkins插件更新应用 到清华源下载插件 https://mirror.tuna.tsinghua.edu.cn/jenkins/plugins/aliyun-container-service-deploy/latest/ 上传插件 等待安装]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-Pipeline]]></title>
    <url>%2FJenkins-Pipeline%2F</url>
    <content type="text"><![CDATA[Jenkins-Pipeline Jenkins Pipeline总体介绍 Pipeline，简而言之，就是一台运行于Jenkins上的工作流框架，将原本独立运行于单个或者多个节点的任务连接起来，实现单个任务难以完成的复杂流程编排与可视化。 Pipeline是Jenkins2.X最核心的特性，帮助Jenkins实现从CI到CD与DevOps的转变。 详细介绍可见https://jenkins.io/2.0 Jenkins Pipeline Jenkins Pipeline是一组插件，让Jenkins可以实现持续交付管道的落地和实施。 持续交付管道（CD Pipeline）是将软件从版本控制阶段到交付给用户或客户的完整过程的自动化表现。 Pipeline提供了一组可扩展的工具，通过Pipeline Domain Specific Language（DSL）syntax可以达到Pipeline as Code的目的 Pipeline as Code： Jenkinsfile 存储在项目的源代码库 核心概念 Node Jenkins节点，或是Master，或是Agent，是执行Step的具体运行环境 Stage 阶段，一个Pipeline可以划分为若干个Stage，每个Stage代表一组操作，如：“Build”，“Test”， “Deploy”。 ​ 注意，Stage是一个逻辑分组的概念，可以跨多个Node。 step 步骤，Step是 最基本的操作单元，小到创建一个目录，大到构建一个Docker镜像，由各类 Jenkins Plugin提供，例如：sh ‘make’ Pipeline特性 代码（Code）: Pipeline以代码的形式实现，通常被检入源代码控制，是团队能够编辑，审查 和迭代其CD流程。 可持续性（Durable）：Jenkins重启或者中断后都不会影响Pipeline Job。 可停顿（Pausable）:Pipeline可以选择停止并等待人工输入或者批准，然后再继续Pipeline运行。 多功能（Versatile）：Pipeline支持实现现实世界的复杂CD要求，包括fork/join子进程，循环和并行执行工作的能力。 可拓展（Extensible）：Pipeline插件支持其DSL的自定义扩展及与其他插件集成的多个选 项。 语法官网文档：https://jenkins.io/doc/book/pipeline/syntax/ 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132pipeline &#123; agent any options &#123; timestamps() &#125; environment &#123; TimeStamp="$&#123;currentBuild.startTimeInMillis&#125;" Service="$&#123;JOB_BASE_NAME&#125;" Branch="$&#123;env.gitlabTargetBranch&#125;" &#125; parameters &#123; choice(name: 'Action',choices: '程序发版\n程序回滚',description: '请选择操作') choice(name: 'Scope',choices: '测试环境\n预发环境\n生产环境\n灾备环境',description: '请选择部署环境') string(name: 'JenkinsApi', defaultValue: 'false', description: '是否是JenkinsAPI触发') string(name: 'BranchOrTag', defaultValue: '', description: '指定分支或tag发版') &#125; stages &#123; stage('PrintEnv') &#123; steps &#123; sh "printenv" &#125; &#125; stage('Check Out') &#123; when &#123; anyOf &#123; environment name: 'Branch',value:'master'; environment name: 'Branch',value:'test'; environment name: 'Scope',value:'测试环境'; environment name: 'Scope',value:'预发环境'; environment name: 'Scope',value:'灾备环境' &#125; &#125; steps &#123; sh "sh jenkins.sh 'CheckOut' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;' '$&#123;BranchOrTag&#125;'" &#125; &#125; stage('Build Package') &#123; when &#123; anyOf &#123; environment name: 'Branch',value:'master'; environment name: 'Branch',value:'test'; environment name: 'Scope',value:'测试环境'; environment name: 'Scope',value:'预发环境'; environment name: 'Scope',value:'灾备环境' &#125; &#125; steps &#123; sh "sh jenkins.sh 'BuildPackage' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;'" &#125; &#125; stage('Build Dockerfile') &#123; when &#123; anyOf &#123; environment name: 'Branch',value:'master'; environment name: 'Branch',value:'test'; environment name: 'Scope',value:'测试环境'; environment name: 'Scope',value:'预发环境'; environment name: 'Scope',value:'生产环境'; environment name: 'Scope',value:'灾备环境' &#125; &#125; steps &#123; sh "sh jenkins.sh 'BuildDockerfile' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;'" &#125; &#125; stage('Build K8S Yaml') &#123; when &#123; anyOf &#123; environment name: 'Branch',value:'master'; environment name: 'Branch',value:'test'; environment name: 'Scope',value:'测试环境'; environment name: 'Scope',value:'预发环境'; environment name: 'Scope',value:'生产环境'; environment name: 'Scope',value:'灾备环境' &#125; &#125; steps &#123; sh "sh jenkins.sh 'BuildK8SYaml' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;' '$&#123;env.Action&#125;'" &#125; &#125; stage('Deploy') &#123; steps &#123; script &#123; if ("$&#123;Scope&#125;" == "测试环境") &#123; echo "测试环境发版" sh "sh jenkins.sh 'DockerBuildPush' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;' '$&#123;env.Action&#125;'" sh "sh jenkins.sh 'Deploy' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;'" &#125; if ("$&#123;Scope&#125;" == "预发环境") &#123; echo "预发环境发版" sh "sh jenkins.sh 'DockerBuildPush' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;' '$&#123;env.Action&#125;'" sh "sh jenkins.sh 'Deploy' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;'" &#125; if ("$&#123;Scope&#125;" == "灾备环境") &#123; echo "灾备环境发版" sh "sh jenkins.sh 'DockerBuildPush' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;' '$&#123;env.Action&#125;'" sh "sh jenkins.sh 'Deploy' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;'" &#125; if ("$&#123;Scope&#125;" == "生产环境") &#123; script &#123; if ("$&#123;JenkinsApi&#125;" == "true") &#123; sh "sh jenkins.sh 'DockerBuildPush' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;' '$&#123;env.Action&#125;'" sh "sh jenkins.sh 'Deploy' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;'" &#125; else &#123; script &#123; if ("$&#123;env.Action&#125;" == "程序回滚") &#123; echo "生产环境回滚,等待领导确认" script &#123; input message: "请确认是否回滚 $&#123;Scope&#125;： ",ok : '确认',submitter: "admin" &#125; echo '已确认，即将回滚' sh "sh jenkins.sh 'Deploy' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;' '$&#123;env.Action&#125;'" &#125; else &#123; echo "生产环境发版,等待领导确认" script &#123; input message: "请确认是否部署 $&#123;Scope&#125;： ",ok : '确认',submitter: "admin" &#125; echo '已确认，即将发布' sh "sh jenkins.sh 'DockerBuildPush' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;' '$&#123;env.Action&#125;'" sh "sh jenkins.sh 'Deploy' '$&#123;Service&#125;' '$&#123;Branch&#125;' '$&#123;Scope&#125;' '$&#123;TimeStamp&#125;'" &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-创建freestyle风格项目]]></title>
    <url>%2FJenkins-%E5%88%9B%E5%BB%BAfreestyle%E9%A3%8E%E6%A0%BC%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[Jenkins-创建freestyle风格项目 创建第一个Job 新建Item 输入名称、选择Job类型 配置Job， 共六部分：通用、源码管理、构建触发器、构建环境、构建、构建后操作 常用操作： 通用：配置参数话构建 源码管理：配置代码仓库地址（git或svn） 构建触发器：配置GitLab的webhook自动触发 构建环境：Delete workspace before build starts 构建：shell脚本或者bat脚本执行任务 构建后操作：邮件通知 参数化构建 Git地址 触发器 构建-shell脚本 保存退出 构建 查看构建状态 查看构建日志 实战分享需求： 项目名称为vdam-web-vip 此job会根据环境不同确定git分支 git clone后编译安装nodejs模块 构建docker镜像，push到镜像仓库 触发应用更新 部署： 创建自由风格项目 名称输入vdam-web-vip 开启参数化构建 配置构建shell 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118set -e## 确定 default.conf 和 nginx.conf文件存在Time=`date +%Y%m%d%H%M%S`WorkDir=`pwd`if [[ $&#123;Scope&#125; == "测试环境" ]]; then Branch="release" ScopeName="test" JavaServiceDomain="test-vdam-gateway-service.fotomore.com"fiif [[ $&#123;Scope&#125; == "预发环境" ]]; then Branch="master" ScopeName="pre" JavaServiceDomain="vdam-gateway-service1.fotomore.com"fiif [[ $&#123;Scope&#125; == "生产环境" ]]; then Branch="master" ScopeName="pro" JavaServiceDomain="vdam-gateway-service.fotomore.com"firm -rf vdam-webmkdir -p vdam-webcd vdam-webgit clone -b $&#123;Branch&#125; git@git.vcg.com:vdam/vue-vip-2019.gitgit clone -b $&#123;Branch&#125; git@git.vcg.com:vdam/vue-admin.gitgit clone -b $&#123;Branch&#125; git@git.vcg.com:vdam/vue-saas.gitgit clone -b $&#123;Branch&#125; git@git.visualchina.com:vdam/vue-vip-upload.gitcd vue-vip-uploadsed -i "s/vdam-gateway.vcg.com/$JavaServiceDomain/g" setBaseUrl.tssed -i "s/vdam-gateway-service.fotomore.com/$JavaServiceDomain/g" setBaseUrl.tssed -i "s/vdam-gateway.fotomore.com/$JavaServiceDomain/g" setBaseUrl.tssed -i "s/vdam-gateway-service.caf79ccb624f24a5cabd1de8623b2e617.cn-beijing.alicontainer.com/$JavaServiceDomain/g" setBaseUrl.tsnpm install --registry https://registry.npm.taobao.orgnpm run buildmv dist ../cd ..mv dist uploadcd vue-vip-2019sed -i "s/vdam-gateway.vcg.com/$JavaServiceDomain/g" setBaseUrl.tssed -i "s/vdam-gateway-service.fotomore.com/$JavaServiceDomain/g" setBaseUrl.tssed -i "s/vdam-gateway.fotomore.com/$JavaServiceDomain/g" setBaseUrl.tssed -i "s/vdam-gateway-service.caf79ccb624f24a5cabd1de8623b2e617.cn-beijing.alicontainer.com/$JavaServiceDomain/g" setBaseUrl.tsnpm install --registry https://registry.npm.taobao.orgnpm run buildmv dist ../cd ..mv dist vipcd vue-adminsed -i "s/vdam-gateway.vcg.com/$JavaServiceDomain/g" src/config/index.jssed -i "s/vdam-gateway-service.fotomore.com/$JavaServiceDomain/g" src/config/index.jssed -i "s/vdam-gateway.fotomore.com/$JavaServiceDomain/g" src/config/index.jssed -i "s/vdam-gateway-service.caf79ccb624f24a5cabd1de8623b2e617.cn-beijing.alicontainer.com/$JavaServiceDomain/g" src/config/index.jsnpm install --registry https://registry.npm.taobao.orgnpm run buildmv dist ../cd ..mv dist admincd vue-saassed -i "s/test-vdam.gateway.vcg.com/$JavaServiceDomain/g" src/config/index.jssed -i "s/vdam-gateway.vcg.com/$JavaServiceDomain/g" src/config/index.jssed -i "s/vdam-gateway-service.fotomore.com/$JavaServiceDomain/g" src/config/index.jssed -i "s/vdam-gateway.fotomore.com/$JavaServiceDomain/g" src/config/index.jssed -i "s/vdam-gateway-service.caf79ccb624f24a5cabd1de8623b2e617.cn-beijing.alicontainer.com/$JavaServiceDomain/g" src/config/index.jsnpm install --registry https://registry.npm.taobao.orgnpm run buildmv dist ../cd ..mv dist saasrm -rf vue-viprm -rf vue-adminrm -rf vue-saascd ..tar zcf vdam-web-vip.tar.gz vdam-web/# cp vdam-web-vip.tar.gz /jenkins/vcgapp/vdam-web-vip/vdam-web-vip.tar.gz-$&#123;Time&#125;cat &gt; Dockerfile &lt;&lt;EOFFROM nginxMAINTAINER hongye.zhao@vcg.comADD vdam-web-vip.tar.gz /usr/share/nginx/html/ADD nginx.conf /etc/nginx/nginx.confADD default.conf /etc/nginx/conf.d/RUN chmod -R 777 /usr/share/nginx/html/EOFdocker build -t registry-vpc.cn-beijing.aliyuncs.com/vcg/vdam-web-vips:$&#123;ScopeName&#125; .docker build -t registry-vpc.cn-beijing.aliyuncs.com/vcg/vdam-web-vips:$&#123;ScopeName&#125;-$Time .docker push registry-vpc.cn-beijing.aliyuncs.com/vcg/vdam-web-vips:$&#123;ScopeName&#125;docker push registry-vpc.cn-beijing.aliyuncs.com/vcg/vdam-web-vips:$&#123;ScopeName&#125;-$Timedocker rmi -f registry-vpc.cn-beijing.aliyuncs.com/vcg/vdam-web-vips:$&#123;ScopeName&#125;docker rmi -f registry-vpc.cn-beijing.aliyuncs.com/vcg/vdam-web-vips:$&#123;ScopeName&#125;-$Timeif [[ $&#123;Scope&#125; == "测试环境" ]]; then curl https://cs.console.aliyun.com/hook/trigger?token=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJjbHVzdGVySWQiOiJjYWY3OWNjYjYyNGYyNGE1Y2FiZDFkZTg2MjNiMmU2MTciLCJpZCI6IjM5NTI2In0.S9KkUgPkymqsc1xclUHFo9zFyd_iLMrKxxEbsPB06lajpw_YSm7aOXAonq_olgP0SxmL6ydiDE5Bu3LuAXjhMCkojXQx4FlnH8uoaBOr2fT9e_RL-4LCGSQLDvoOFqQQ1csBfPi2UpT6oDh_KkxvaYoF7kqvTmpClF2XQO9X9f4 #curl https://cs.console.aliyun.com/hook/trigger?token=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJjbHVzdGVySWQiOiJjYWY3OWNjYjYyNGYyNGE1Y2FiZDFkZTg2MjNiMmU2MTciLCJpZCI6IjMyNzQ0In0.afM-iP1cZUVBDdIefzca6SJyIfFBPO3hqcC0HgrJPcaQLkvmFQYuHAgF6OHKgdHLa0rErRvcKgq1t_6g4DhBiql5EN9qQYAiAKEwXTpfc-0tiNfZg4w2Z4mybg-MeiduZCD0Reh1hUy-jdNNg58poR-IeKJZRhT3IlmfIp4Ssisfiif [[ $&#123;Scope&#125; == "预发环境" ]]; then curl https://cs.console.aliyun.com/hook/trigger?token=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJjbHVzdGVySWQiOiJjMmFiNDFlZWE0YjgxNDNlZmEwMzg3OWZiNDlhOWEyODIiLCJpZCI6IjM5NTI1In0.nwNJTY-9jPhbnVe1_4fTUuCXPd5JlkRlvGgQC8GD-u1qBqsousj8wsO65s6xhksW0h1PBPVnTn8QelwgCLMLyIvN8Pv_H7uB2x4tGHudZHjrPxKURgU6cwH4SnXhd3VYOdfd-Qc3sMKAe9aG_HoKwQoC2Zj2yT3kTQEB7j7Mlv0 #curl https://cs.console.aliyun.com/hook/trigger?token=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJjbHVzdGVySWQiOiJjMmFiNDFlZWE0YjgxNDNlZmEwMzg3OWZiNDlhOWEyODIiLCJpZCI6IjM3MDcyIn0.Dxx3lVTAysaRBtI6jcDLMm0M0Yh239eUznxq4dpUIIjhDsKLlgtN-UJt0TIBOmAucj8XnBjI_T-mX7hy6WrHH8bKREyMz6cWrGutfBQqNYQ2j-HyScP-Q8tsqO1q4XZuuS9__BB2-mDoN0xqqFUAAITkDkmw702rfRpbIolvNu4fiif [[ $&#123;Scope&#125; == "生产环境" ]]; then echo "" curl https://cs.console.aliyun.com/hook/trigger?token=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJjbHVzdGVySWQiOiJjNDY0MTNjYjEzYmIzNDkwZGEzZTQ5NWU0MjY0ZjZkMTkiLCJpZCI6IjM3MTkzIn0.HJfnm1ujwLRYnQpsRpiXLErKi2gE_glnZBcss9c2zmHGv-_Gcl6vYLRPdmnPpvcU2cVkuKgExHUUFGdNqzkKDEeFu8lBez9c2gCWi7l81KNAFhsgtTIEm8YRpi9p92kIsutjD_AEj6UuY_jy58nvIWGeXRtuYAaWJGXFQ6B5ItEfi 保存退出 参数化构建 验证ok]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins-安装]]></title>
    <url>%2FJenkins-%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Jenkins-安装 官方安装文档 安装部署： jdk + war包 jdk + tomcat + war包 docker JDK+War包 安装JDK 源码安装： oracle官网获取JDK安装包，jdk-8u211-linux-x64.tar.gz，并上传到服务器。 123456789101112131415# 服务器软件目录 /data/vcg/# 1、解压tar zxf jdk-8u211-linux-x64.tar.gz# 2、配置环境变量 /etc/profilevim /etc/profile添加如下内容：#jdkexport JAVA_HOME=/data/vcg/jdk1.8.0_211export CLASSPATH=.:$JAVA_HOME/jar/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$PATH# 3、重新加载配置文件source /etc/profile# 4、验证java -version YUM安装 1yum install -y java-1.8.0-openjdk.x86_64 获取Jenkins war包 Jenkins官网获取下载链接，或直接下载程序包，然后scp上传到服务器待用。 1wget https://mirrors.tuna.tsinghua.edu.cn/jenkins/war-stable/2.176.1/jenkins.war 启动Jenkins 1java -jar jenkins.war 12后台启动：nohup java -jar jenkins.war &amp; 访问ip:8080/jenkins JDK+Tomcat+War包 安装JDK1yum install -y java-1.8.0-openjdk.x86_64 安装Tomcatapache官网获取Tomcat安装包，apache-tomcat-8.5.42.tar.gz，并上传到服务器。 12345678# 服务器软件目录 /data/vcg/# wgetwget http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.42/bin/apache-tomcat-8.5.42.tar.gz# 解压tar zxf apache-tomcat-8.5.42.tar.gz# 重命名mv apache-tomcat-8.5.42 tomcat 获取Jenkins war包 1wget https://mirrors.tuna.tsinghua.edu.cn/jenkins/war-stable/2.176.1/jenkins.war 将Jenkins war包放到tomcat下 1cp jenkins.war /data/vcg/tomcat/webapps 启动tomcat 1sh /data/vcg/tomcat/bin/startup.sh 访问ip:8080/jenkins Docker123456789docker run \ -u root \ --rm \ -d \ -p 8080:8080 \ -p 50000:50000 \ -v jenkins-data:/var/jenkins_home \ -v /var/run/docker.sock:/var/run/docker.sock \ jenkinsci/blueocean 配置Jenkins 解锁 安装插件 等待插件安装———————— 创建管理员用户 一般选择 “使用admin账号继续” 安装完成 重置管理员密码默认admin密码保存在.jenkins/secrets/initialAdminPassword 登录jenkins后，在“用户列表”—&gt;”admin”—&gt;”设置”的配置页中，找到Password配置项，输入新的密码后保存即可。]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab-管理员密码重置]]></title>
    <url>%2FGitLab-%E7%AE%A1%E7%90%86%E5%91%98%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[官方文档地址：https://docs.gitlab.com/ce/security/reset_root_password.html 操作如下： 1gitlab-rails console production 1user = User.where(id: 1).first 123456user.password = &apos;secret_pass&apos;user.password_confirmation = &apos;secret_pass&apos;例如：user.password = 123456789user.password_confirmation = 123456789 1user.save!]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab旧版本安装]]></title>
    <url>%2FGitLab%E6%97%A7%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[需求研发需要找老代码，找到备份文件后恢复时报错版本过低 操作 下载安装包https://packages.gitlab.com/gitlab/gitlab-ce找到对应的版本，下载到服务器 安装 1rpm -ivh gitlab-ce-8.6.6-ce.0.el7.x86_64.rpm 恢复数据 1gitlab-rake gitlab:backup:restore RAILS_ENV=production BACKUP=1561606164]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修复漏洞-提升RDS响应速度]]></title>
    <url>%2F%E4%BF%AE%E5%A4%8D%E6%BC%8F%E6%B4%9E-%E6%8F%90%E5%8D%87RDS%E5%93%8D%E5%BA%94%E9%80%9F%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[需求： 升级linux内核版本，修复SACK Panic”远程DoS漏洞 安装nscd，提升RDS响应速度 说明：漏洞描述：Linux 以及 FreeBSD 等系统内核上存在严重远程DoS漏洞，攻击者可利用该漏洞构造并发送特定的 SACK 序列请求到目标服务器导致服务器崩溃或拒绝服务。 目前已知受影响版本如下： • FreeBSD 12（使用到 RACK TCP 协议栈） • CentOS 5（Redhat 官方已停止支持，不再提供补丁） • CentOS 6 • CentOS 7 • Ubuntu 18.04 LTS • Ubuntu 16.04 LTS • Ubuntu 19.04 • Ubuntu 18.10各大Linux发行厂商已发布内核修复补丁，详细内核修复版本如下： • CentOS 6 ：2.6.32-754.15.3 • CentOS 7 ：3.10.0-957.21.3 • Ubuntu 18.04 LTS ：4.15.0-52.56 • Ubuntu 16.04 LTS：4.4.0-151.178 修复建议：➤【CentOS 6/7 系列用户】注：截止文章发布，CentOS官方暂未同步内核修复补丁到软件源，建议用户及时关注补丁更新情况并开展相应升级工作。升级方式如下： yum clean all &amp;&amp; yum makecache，进行软件源更新； yum update kernel -y，更新当前内核版本; reboot，更新后重启系统生效; uname -a，检查当前版本是否为上述【安全版本】，如果是，则说明修复成功。 ➤【Ubuntu 16.06/18.04 LTS 系列用户】 sudo apt-get update &amp;&amp; sudo apt-get install linux-image-generic，进行软件源更新并安装最新内核版本； sudo reboot，更新后重启系统生效； uname -a，检查当前版本是否为【安全版本】，如果是，则说明修复成功。如果用户不方便重启进行内核补丁更新，可选择临时缓解方案：运行如下命令禁用内核 SACK 配置防范漏洞利用：sysctl -w net.ipv4.tcp_sack=0 NSCD服务：https://help.aliyun.com/knowledge_detail/41806.html NSCD（Name Service Cache Daemon）是一种能够缓存passwd、group、hosts的本地缓存服务。若您使用短连接的方式连接RDS，请在与RDS相连的ECS实例上进行如下操作开启NSCD，提升RDS响应速度。 思路： 编写Shell脚本 Ansible分发脚本 Ansible执行脚本 验证脚本执行情况 分批重启主机 实现：Shell脚本：1234567vim /data/vcg/zhy/ansible/0623.shyum clean all &amp;&amp; yum makecacheyum update -y # 或者 yum update kernel -yyum install -y nscdsystemctl enable nscd.serviceecho "options timeout:1 attempts:1" &gt;&gt; /etc/resolv.conf 分发脚本1ansible pre-k8s -m copy -a "src=/data/vcg/zhy/ansible/0623.sh dest=/tmp/0623.sh mode=755" 执行脚本1ansible pre-k8s -m shell -a "/tmp/0623.sh" 验证脚本执行情况1ansible pre-k8s -m shell -a "cat /etc/resolv.conf |grep options" 分批重启主机12345678910111213141516171819#脚本内容：hosts="172.20.21.249172.20.21.250172.20.21.251172.20.21.252172.20.21.253172.20.21.254172.20.21.255172.20.22.0172.20.22.1172.20.22.2"for i in $hosts;do ssh $i uptime ssh $i reboot sleep 2m ssh $i uptimedone]]></content>
  </entry>
  <entry>
    <title><![CDATA[神策logagent收集Kubernetes-Pod日志]]></title>
    <url>%2F%E7%A5%9E%E7%AD%96logagent%E6%94%B6%E9%9B%86Kubernetes-Pod%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[神策logagent收集Kubernetes Pod日志 项目背景：神策logagent需要收集到java程序输出的日志，用于分析用户行为等 想到两种方案 pod指定部署到某台宿主机上，日志目录挂载到宿主机，宿主机上启动logagent程序。 sidecar的形式 目前使用第一种方案，比较稳妥，后续技术扎实后会替换成第二种，更稳定高效。 部署logagent官方部署文档 安装Jdk1yum install -y java-1.8.0-openjdk.x86_64 下载LogAgent部署包和解压12wget http://download.sensorsdata.cn/release/logagent/logagent_20190605.tgztar zxvf logagent_20190605.tgz 编辑配置文件123456789vim logagent/logagent.confpath=/var/log/veercms #本地路径logagent_id=veerservice_2_241 #idpattern=cms.veerservice.log* #log名称格式project=productionpid_file=/data/vcg/logagent/logagent.pidhost=172.16.249.136 #server端地址port=8106 启动1nohup bin/logagent &gt;/dev/null 2&gt;&amp;1 &amp; 查看日志1tail -f /data/vcg/logagent/log/logagent.log 配置节点标签两种方式实现： 控制台上添加标签 命令行 12345#例如给 cn-beijing.i-2ze7nm52ylwxd8j4d0lq 这个node添加标签：kubectl label nodes cn-beijing.i-2ze7nm52ylwxd8j4d0lq test-key=test-value#查看标签：kubectl get node --show-labels 配置k8s yaml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091---apiVersion: apps/v1beta2kind: Deploymentmetadata: name: com-veer-veerservice labels: app: com-veer-veerservice namespace: defaultspec: replicas: 6 selector: matchLabels: app: com-veer-veerservice template: metadata: labels: app: com-veer-veerservice spec: dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: &#123;&#125; terminationGracePeriodSeconds: 30 imagePullSecrets: - name: registry-vpc.cn-beijing.aliyuncs.com ## 保密字典中的仓储认证 affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - preference: &#123;&#125; weight: 100 requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: vcgapp operator: In values: - veerlogagent ## node节点亲和性 containers: - name: com-veer-veerservice image: 'registry-vpc.cn-beijing.aliyuncs.com/vcg/com-veer-veerservice:pro-20190610183629' ## 镜像地址 env: - name: aliyun_logs_com-veer-veerservice ## 日志服务 value: stdout imagePullPolicy: Always volumeMounts: - mountPath: /var/log/veerservice_log # 容器内路径 name: volume-veerservice resources: limits: cpu: '1' memory: 4Gi requests: cpu: 500m memory: 1000Mi livenessProbe: ## 存活检测 initialDelaySeconds: 80 periodSeconds: 10 timeoutSeconds: 1 successThreshold: 1 failureThreshold: 3 tcpSocket: port: 9101 readinessProbe: ## 就绪检测 initialDelaySeconds: 80 periodSeconds: 10 timeoutSeconds: 1 successThreshold: 1 failureThreshold: 3 tcpSocket: port: 9101 volumes: - hostPath: path: /var/log/veerservice # 主机路径 type: '' name: volume-veerservice---apiVersion: v1kind: Servicemetadata: name: com-veer-veerservice labels: app: com-veer-veerservice namespace: defaultspec: selector: app: com-veer-veerservice ports: - port: 80 protocol: TCP targetPort: 9101 type: ClusterIP]]></content>
  </entry>
  <entry>
    <title><![CDATA[阿里云OSS对象存储中的图片数据迁移到京东云OSS]]></title>
    <url>%2F%E9%98%BF%E9%87%8C%E4%BA%91OSS%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%B8%AD%E7%9A%84%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E5%88%B0%E4%BA%AC%E4%B8%9C%E4%BA%91OSS%2F</url>
    <content type="text"><![CDATA[阿里云OSS对象存储中的图片数据迁移到京东云OSS 下载数据使用阿里云提供的 ossutil 工具进行下载操作 1ossutil cp oss://static-vcg/veer/static/ veer/static/ 上传数据使用Amazon提供的 s3cmd 工具进行上传操作 1s3cmd put --recursive static/ s3://vcg-veer-static/static/ 异常问题上传到京东云后发现浏览器访问oss里的图片，会以下载的形式展示，需要更改为在线展示。 询问京东技术后重新上传，增加 –content-type=”image/svg+xml”参数 1nohup s3cmd put --recursive --content-type=&quot;image/svg+xml&quot; static/ s3://vcg-veer-static/static/ &amp; 重新上传后，清除本地缓存，刷新CDN目录或指定资源即可正常访问。 调用京东云SDK获取OSS文件的属性SDK-Python 安装pip和boto31pip install boto3 创建client 123456789101112import boto3 ACCESS_KEY = 'your accesskey' SECRET_KEY = 'your secretkey' s3 = boto3.client( 's3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY, #下面给出一个endpoint_url的例子 endpoint_url='https://s3.cn-north-1.jdcloud-oss.com' ) s3.head_object(Bucket='vcg-veer-static',Key='static/landing/icon_search_white.svg') 返回值如下：]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python-调用阿里云API实现Swarm集群应用的更新或重启]]></title>
    <url>%2FPython-%E8%B0%83%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91API%E5%AE%9E%E7%8E%B0Swarm%E9%9B%86%E7%BE%A4%E5%BA%94%E7%94%A8%E7%9A%84%E6%9B%B4%E6%96%B0%E6%88%96%E9%87%8D%E5%90%AF%2F</url>
    <content type="text"><![CDATA[需求调用阿里云API实现 根据docker compose文件进行Swarm集群容器应用的更新、重启 脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226#!/usr/bin/env python# -*- coding:utf-8 -*-#调用阿里容器api'''alics.py参数1 操作 update restart参数2 集群名称 pre test pro参数2 应用名称参数3 dockercompose文件的绝对路径参数4 时间戳'''import requestsimport sysimport jsonimport timeimport sysreload(sys)sys.setdefaultencoding("utf-8")Action=sys.argv[1]TimeStamp=str(time.time())def UpdataService(ClusterName,Service,File,TimeStamp): with open(File) as file: contents = file.read().replace('\n', '\r\n') data = &#123; "template": contents, "version": TimeStamp, &#125; if ClusterName == "pre": print '预发环境的 %s 应用进行更新' % Service url = 'https://master2g11.cs.cn-beijing.aliyuncs.com:20060/projects/' + Service + '/update' verify = '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/key.pem') elif ClusterName == "pro": print '生产环境的 %s 应用进行更新' % Service url = 'https://master4g5.cs-cn-beijing.aliyun.com:20045/projects/' + Service + '/update' verify = '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/key.pem') elif ClusterName == "test": print '测试环境的 %s 应用进行更新' % Service url = 'https://master1g8.cs-cn-hangzhou.aliyun.com:20034/projects/' + Service + '/update' verify = '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/key.pem') res = requests.post(url,data=json.dumps(data),verify=verify,cert=cert) print res print res.text if '202' in str(res): print '\n应用更新请求已发送到阿里云容器服务！\n' sys.exit(0) else: print '更新失败，请查看compose文件是否缺少参数' sys.exit(1)def CreateService(ClusterName,Service,File,TimeStamp): with open(File) as file: contents = file.read().replace('\n', '\r\n') data = &#123; "name": Service, "template": contents, "version": TimeStamp, &#125; if ClusterName == "pre": print '创建预发环境的 %s 应用' % Service url = 'https://master2g11.cs.cn-beijing.aliyuncs.com:20060/projects/' verify = '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/key.pem') elif ClusterName == "pro": print '创建生产环境的 %s 应用' % Service url = 'https://master4g5.cs-cn-beijing.aliyun.com:20045/projects/' verify = '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/key.pem') elif ClusterName == "test": print '创建测试环境的 %s 应用' % Service url = 'https://master1g8.cs-cn-hangzhou.aliyun.com:20034/projects/' verify = '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/key.pem') res = requests.post(url,data=json.dumps(data),verify=verify,cert=cert) print res print res.text if '201' in str(res): print '\n应用更新请求已发送到阿里云容器服务！\n' sys.exit(0) else: print '更新失败，请查看compose文件是否缺少参数' sys.exit(1)def RestartService(ClusterName,Service): if ClusterName == "pre": print '预发环境的 %s 应用进行重启' % Service url = 'https://master2g11.cs.cn-beijing.aliyuncs.com:20060/projects/' + Service + '/restart' verify = '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/key.pem') elif ClusterName == "pro": print '生产环境的 %s 应用进行重启' % Service url = 'https://master4g5.cs-cn-beijing.aliyun.com:20045/projects/' + Service + '/restart' verify = '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/key.pem') elif ClusterName == "test": print '测试环境的 %s 应用进行重启' % Service url = 'https://master1g8.cs-cn-hangzhou.aliyun.com:20034/projects/' + Service + '/restart' verify = '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/key.pem') while True: res = requests.post(url,verify=verify,cert=cert) print res print res.text if '200' in str(res): print '\n应用重启完成！\n' break else: print '程序正在更新，10秒后重试！' time.sleep( 10 )def GetService(ClusterName,Service): if ClusterName == "pre": print '获取预发环境的 %s 应用的信息' % Service url = 'https://master2g11.cs.cn-beijing.aliyuncs.com:20060/projects/' + Service verify = '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/key.pem') elif ClusterName == "pro": print '获取生产环境的 %s 应用的信息' % Service url = 'https://master4g5.cs-cn-beijing.aliyun.com:20045/projects/' + Service verify = '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/key.pem') elif ClusterName == "test": print '获取测试环境的 %s 应用的信息' % Service url = 'https://master1g8.cs-cn-hangzhou.aliyun.com:20034/projects/' + Service verify = '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/key.pem') res = requests.get(url,verify=verify,cert=cert) print res print json.loads(res.text)def RedeployService(ClusterName,Service): if ClusterName == "pre": print '预发环境的 %s 应用进行重新部署' % Service url = 'https://master2g11.cs.cn-beijing.aliyuncs.com:20060/projects/' + Service + '/redeploy' verify = '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/key.pem') elif ClusterName == "pro": print '生产环境的 %s 应用进行重新部署' % Service url = 'https://master4g5.cs-cn-beijing.aliyun.com:20045/projects/' + Service + '/redeploy' verify = '/vcgapp/ops/sdk/swarm/vcg-com/ca.pem' cert = ('/vcgapp/ops/sdk/swarm/vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/key.pem') elif ClusterName == "test": print '测试环境的 %s 应用进行重新部署' % Service url = 'https://master1g8.cs-cn-hangzhou.aliyun.com:20034/projects/' + Service + '/redeploy' verify = '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/test-vcg-com/key.pem') res = requests.post(url,verify=verify,cert=cert) print res print res.textdef GetComposeService(ClusterName,Service): if ClusterName == "pre": File = '/jenkins/vcgapp/compose-back/pre/' + Service print '获取预发环境的 %s 应用的Compose文件，保存本地后的文件为 %s' % (Service,File) url = 'https://master2g11.cs.cn-beijing.aliyuncs.com:20060/projects/' + Service verify = '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/cert.pem', '/vcgapp/ops/sdk/swarm/pre-vcg-com/key.pem') elif ClusterName == "pro": File = '/jenkins/vcgapp/compose-back/pro/' + Service print '获取生产环境的 %s 应用的Compose文件，保存本地后的文件为 %s' % (Service,File) url = 'https://master4g5.cs-cn-beijing.aliyun.com:20045/projects/' + Service verify = '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/vcg-com/cert.pem', '/vcgapp/ops/sdk/swarm/vcg-com/key.pem') res = requests.get(url,verify=verify,cert=cert) with open(File,'w') as file: file.write(json.loads(res.text).get('template').replace('\r\n','\n'))def GetAllService(ClusterName): if ClusterName == "pre": print '获取预发环境所有应用的信息' url = 'https://master2g11.cs.cn-beijing.aliyuncs.com:20060/projects/' verify = '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/pre-vcg-com/key.pem') elif ClusterName == "pro": print '获取生产环境所有应用的信息' url = 'https://master4g5.cs-cn-beijing.aliyun.com:20045/projects/' verify = '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/ca.pem' cert = ('/jenkins/vcgapp/ops/sdk/swarm/vcg-com/cert.pem', '/jenkins/vcgapp/ops/sdk/swarm/vcg-com/key.pem') res = requests.get(url,verify=verify,cert=cert) print res #print res.text for i in json.loads(res.text): #print i.get('template').replace('\r\n','\n') if ClusterName == "pre": File = '/jenkins/vcgapp/compose-back/pre/' + i.get('name') elif ClusterName == "pro": File = '/jenkins/vcgapp/compose-back/pro/' + i.get('name') composefile = i.get('template').replace('\r\n','\n') with open(File,'w') as file: file.write(composefile) print "%s 的 compose 文件已备份到 %s " % (i.get('name'),File)if Action == "update": ClusterName = sys.argv[2] Service = sys.argv[3] File = sys.argv[4] UpdataService(ClusterName,Service,File,TimeStamp)elif Action == "create": ClusterName = sys.argv[2] Service = sys.argv[3] File = sys.argv[4] CreateService(ClusterName,Service,File,TimeStamp)elif Action == "restart": ClusterName = sys.argv[2] Service = sys.argv[3] RestartService(ClusterName, Service)elif Action == "getinfo": ClusterName = sys.argv[2] Service = sys.argv[3] GetService(ClusterName, Service)elif Action == "redeploy": ClusterName = sys.argv[2] Service = sys.argv[3] RedeployService(ClusterName, Service)elif Action == "getcompose": ClusterName = sys.argv[2] Service = sys.argv[3] GetComposeService(ClusterName, Service)elif Action == "getallservice": ClusterName = sys.argv[2] GetAllService(ClusterName)]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python-脚本调用阿里SDK实现控制SLB]]></title>
    <url>%2FPython-%E8%84%9A%E6%9C%AC%E8%B0%83%E7%94%A8%E9%98%BF%E9%87%8CSDK%E5%AE%9E%E7%8E%B0%E6%8E%A7%E5%88%B6SLB%2F</url>
    <content type="text"><![CDATA[需求今天哥们提了一个需求，想实现调阿里云SLB的SDK实现脚本调整权重、增加或移除后端ECS实例 脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122# -*- coding: utf-8 -*-#安装python3和pip#安装以下sdk模块#pip install aliyun-python-sdk-core-v3#pip install aliyun-python-sdk-slbimport sysimport jsonfrom aliyunsdkcore.client import AcsClientfrom aliyunsdkslb.request.v20140515 import DescribeLoadBalancersRequestfrom aliyunsdkslb.request.v20140515 import DescribeLoadBalancerAttributeRequestfrom aliyunsdkslb.request.v20140515 import SetBackendServersRequestfrom aliyunsdkslb.request.v20140515 import AddBackendServersRequestfrom aliyunsdkslb.request.v20140515 import RemoveBackendServersRequest# 需填写ak信息，可用区AccessKey=''AccessKeySecret=''RegionId = "cn-beijing"client = AcsClient(AccessKey,AccessKeySecret,RegionId);helpInfo='''Basic Commands : get 获取SLB信息 edit 配置SLB的后端权重 add 添加SLB的后端实例 remove 删除SLB的后端实例Usage: 获取所有实例的信息 python slb-0604.py get all 获取某一实例的信息 python slb-0604.py get lb-2zedfhvgznrm7eqbr00uv 编辑单个权重 python slb-0604.py edit lb-2zedfhvgznrm7eqbr00uv [&#123;'ServerId': 'i-2zedna91yczcq12zm60q', 'Weight': 99, 'Type': 'ecs'&#125;] 编辑多个权重（最多20个） python slb-0604.py edit lb-2zedfhvgznrm7eqbr00uv [&#123;"ServerId":"i-2zej4lxhjoq1icue6kup","Weight":"100"&#125;,&#123;"ServerId":"i-2ze1u9ywulp5pbvvc7hv","Weight":"100"&#125;] 添加单个后端ecs python slb-0604.py add lb-2zedfhvgznrm7eqbr00uv [&#123;"ServerId":"i-2ze1u9ywulp5pbvvc7hv","Weight":"100"&#125;] 添加多个后端ecs python slb-0604.py add lb-2zedfhvgznrm7eqbr00uv [&#123;"ServerId":"i-2zej4lxhjoq1icue6kup","Weight":"100"&#125;,&#123;"ServerId":"i-2ze1u9ywulp5pbvvc7hv","Weight":"100"&#125;] 删除后端ecs python slb-0604.py remove lb-2zedfhvgznrm7eqbr00uv [&#123;"ServerId":"i-2zej4lxhjoq1icue6kup","Weight":"100"&#125;,&#123;"ServerId":"i-2ze1u9ywulp5pbvvc7hv","Weight":"100"&#125;]'''def main(): print(helpInfo)def DescribeLoadBalancers(resource): request = DescribeLoadBalancersRequest.DescribeLoadBalancersRequest() response = client.do_action_with_exception(request) SLBInfo = json.loads(response) LoadBalancerIdList = [] for SLBInstance in SLBInfo['LoadBalancers']['LoadBalancer']: LoadBalancerIdList.append(SLBInstance['LoadBalancerId']) if resource == 'all': Ali_Slb_Info = &#123;&#125; for SLBInstance in SLBInfo['LoadBalancers']['LoadBalancer']: request = DescribeLoadBalancerAttributeRequest.DescribeLoadBalancerAttributeRequest() request.set_LoadBalancerId(SLBInstance['LoadBalancerId']) response = client.do_action_with_exception(request) Ali_Slb_Info[SLBInstance['LoadBalancerId']] = json.loads(response.decode('utf-8')) print(LoadBalancerIdList) elif resource in LoadBalancerIdList: request = DescribeLoadBalancerAttributeRequest.DescribeLoadBalancerAttributeRequest() request.set_LoadBalancerId(resource) response = client.do_action_with_exception(request) response = json.loads(response.decode('utf-8')) print(response['BackendServers']) else: print("输入错误,请输入 all 或 SLB实例ID ！")def SetBackendServers(resource,BackendServers): request = SetBackendServersRequest.SetBackendServersRequest() request.set_accept_format('json') request.set_BackendServers(BackendServers) request.set_LoadBalancerId(resource) response = client.do_action_with_exception(request) print(str(response, encoding='utf-8'))def AddBackendServers(resource,BackendServers): request = AddBackendServersRequest() request.set_accept_format('json') request.set_BackendServers(BackendServers) request.set_LoadBalancerId(resource) response = client.do_action_with_exception(request) print(str(response, encoding='utf-8'))def RemoveBackendServers(resource,BackendServers): request = RemoveBackendServersRequest() request.set_accept_format('json') request.set_BackendServers(BackendServers) request.set_LoadBalancerId(resource) response = client.do_action_with_exception(request) print(str(response, encoding='utf-8'))if __name__ == '__main__': if len(sys.argv) == 1: main() else: userInput = sys.argv[1:] if userInput[0] == 'get' and userInput[1]: resource = userInput[1] DescribeLoadBalancers(resource) if userInput[0] == 'edit' and userInput[1] and userInput[2]: resource = userInput[1] BackendServers = userInput[2] SetBackendServers(resource,BackendServers) if userInput[0] == 'add' and userInput[1] and userInput[2]: resource = userInput[1] BackendServers = userInput[2] AddBackendServers(resource,BackendServers) if userInput[0] == 'remove' and userInput[1] and userInput[2]: resource = userInput[1] BackendServers = userInput[2] RemoveBackendServers(resource,BackendServers) else: print("输入错误")]]></content>
  </entry>
  <entry>
    <title><![CDATA[Shell脚本-定期删除异常Pod]]></title>
    <url>%2FShell%E8%84%9A%E6%9C%AC-%E5%AE%9A%E6%9C%9F%E5%88%A0%E9%99%A4%E5%BC%82%E5%B8%B8Pod%2F</url>
    <content type="text"><![CDATA[需求有的Pod重启次数过多 12345678[cicd-test@ops-jenkins-master ~]$ kubectl get pods |awk '&#123;if ($4 &gt;= 1) print $0 &#125;'NAME READY STATUS RESTARTS AGEcmsservice-vcg-com-57974bc4cf-vq6mk 1/1 Running 1 6m18sedgeservice-vcg-com-755b96fb78-v96s5 1/1 Running 1 3d23hedgeserviceweb-vcg-com-5655fc9899-8lxql 1/1 Running 1 3d23hnode-visualchina-web-8575cf78dc-8jr2k 1/1 Running 1 4h11mvdam-gateway-service-6b7d864d67-rdzrg 1/1 Running 1 3h36mvdam-passport-service-7c97d84b58-xhn6k 1/1 Running 6 3d22h 脚本12345678910111213141516171819202122232425262728#!/bin/bash#Author:zhy#Version:1.0#Date:20190603#########删除重启次数超过5次的PODset -eTime=`date +%Y%m%d%H%M%S`echo $Time &gt;&gt; /home/cicd-pro/cron/k8s_pod_restart.logif [[ `/usr/local/bin/kubectl --kubeconfig /home/cicd-pro/.kube/config get pods | awk '&#123;if ($4 &gt;= 5) print $0 &#125;' |grep -v 'NAME' |wc -l` -eq 0 ]];then echo '无重启次数超过5次的POD' echo '无重启次数超过5次的POD' &gt;&gt; /home/cicd-pro/cron/k8s_pod_restart.logelse echo '将要删除如下pod：' echo '将要删除如下pod：' &gt;&gt; /home/cicd-pro/cron/k8s_pod_restart.log /usr/local/bin/kubectl --kubeconfig /home/cicd-pro/.kube/config get pods | awk '&#123;if ($4 &gt;= 5) print $1 &#125;'| grep -v 'NAME' echo `/usr/local/bin/kubectl --kubeconfig /home/cicd-pro/.kube/config get pods | awk '&#123;if ($4 &gt;= 5) print $1 &#125;'| grep -v 'NAME'` &gt;&gt; /home/cicd-pro/cron/k8s_pod_restart.log for i in `/usr/local/bin/kubectl --kubeconfig /home/cicd-pro/.kube/config get pods | awk '&#123;if ($4 &gt;= 5) print $1 &#125;' | grep -v 'NAME'`; do echo $i /usr/local/bin/kubectl --kubeconfig /home/cicd-pro/.kube/config delete pod $i donefi]]></content>
  </entry>
  <entry>
    <title><![CDATA[奇葩需求-jenkins脚本]]></title>
    <url>%2F%E5%A5%87%E8%91%A9%E9%9C%80%E6%B1%82-jenkins%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[jenkins 项目中的shell脚本： 实现 自动构建后 访问微服务可以获取 Kubernetes pod镜像地址 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657set -eTime=`date +%Y%m%d%H%M%S`WorkDir=`pwd`if [[ $&#123;Scope&#125; == "测试环境" ]]; then Branch="release" ScopeName="test"fiif [[ $&#123;Scope&#125; == "预发环境" ]]; then Branch="master" ScopeName="pre"fiif [[ $&#123;Scope&#125; == "生产环境" ]]; then Branch="master" ScopeName="pro"ficat &gt; Dockerfile &lt;&lt;EOFFROM registry-vpc.cn-beijing.aliyuncs.com/vcgcs/flaskWORKDIR /usr/src/appADD . .CMD python manager.pyEOFcat &gt; manager.py &lt;&lt;EOFfrom flask import Flaskfrom flask import requestimport osapp = Flask(__name__)@app.route('/',methods=["GET"])def cicd_test(): if request.method == 'GET': test = os.popen("/usr/src/app/kubectl --kubeconfig /usr/src/app/test-config get deployment cicd-test -o yaml |grep image |grep aliyuncs |awk -F '- image:' '&#123;print \$2&#125;'").read() pre = os.popen("/usr/src/app/kubectl --kubeconfig /usr/src/app/pre-config get deployment cicd-test -o yaml |grep image |grep aliyuncs |awk -F '- image:' '&#123;print \$2&#125;'").read() pro = os.popen("/usr/src/app/kubectl --kubeconfig /usr/src/app/pro-config get deployment cicd-test -o yaml |grep image |grep aliyuncs |awk -F '- image:' '&#123;print \$2&#125;'").read() return "test环境的镜像地址: %s ,pre环境的镜像地址: %s , pro环境的镜像地址: %s" % (test,pre,pro)if __name__ == '__main__': app.run(host='0.0.0.0',port='5001',debug=True)EOFdocker build -t registry-vpc.cn-beijing.aliyuncs.com/vcg/cicd-test:$&#123;ScopeName&#125;-$Time .docker push registry-vpc.cn-beijing.aliyuncs.com/vcg/cicd-test:$&#123;ScopeName&#125;-$Timedocker rmi -f registry-vpc.cn-beijing.aliyuncs.com/vcg/cicd-test:$&#123;ScopeName&#125;-$Timeif [[ $&#123;Scope&#125; == "测试环境" ]]; then su - cicd-test -c "kubectl set image deployment cicd-test cicd-test=registry-vpc.cn-beijing.aliyuncs.com/vcg/cicd-test:$&#123;ScopeName&#125;-$Time"fiif [[ $&#123;Scope&#125; == "预发环境" ]]; then su - cicd-pre -c "kubectl set image deployment cicd-test cicd-test=registry-vpc.cn-beijing.aliyuncs.com/vcg/cicd-test:$&#123;ScopeName&#125;-$Time"fiif [[ $&#123;Scope&#125; == "生产环境" ]]; then su - cicd-pro -c "kubectl set image deployment cicd-test cicd-test=registry-vpc.cn-beijing.aliyuncs.com/vcg/cicd-test:$&#123;ScopeName&#125;-$Time"fi 效果为： 1test环境的镜像地址: registry-vpc.cn-beijing.aliyuncs.com/vcg/cicd-test:test-20190530160557 ,pre环境的镜像地址: registry-vpc.cn-beijing.aliyuncs.com/vcg/cicd-test:pre-20190530162226 , pro环境的镜像地址: registry-vpc.cn-beijing.aliyuncs.com/vcg/cicd-test:pro-20190530162233]]></content>
      <tags>
        <tag>Jenkins</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx-日志切割]]></title>
    <url>%2FNginx-%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%2F</url>
    <content type="text"><![CDATA[nginx日志按天进行切割，通过写shell脚本，创建以日期命名文件 12345678910111213141516171819202122232425262728293031#!/usr/bin/env bashset -e# 定义nginx 日志路径LOG_PATH="/var/gb/logs/"# 定义nginx 访问日志文件名称ACCESS_LOG="access.log"ERROR_LOG="error.log"for i in `find $LOG_PATH -name "$ACCESS_LOG"`; do cd $(dirname $i) # 切割access日志 if [[ -f $ACCESS_LOG ]]; then cp &#123;,$(date +%F)-&#125;$&#123;ACCESS_LOG&#125; : &gt; $ACCESS_LOG fi # 如果error日志&gt;20m，切 if [[ -f $ERROR_LOG ]]; then ERROR_SIZE=`ls -l $ERROR_LOG | awk '&#123; print $5 &#125;'` if [[ $ERROR_SIZE -gt 20971520 ]]; then cp &#123;,$(date +%F)-&#125;$&#123;ERROR_LOG&#125; : &gt; $&#123;ERROR_LOG&#125; fi fidone# 查找nginx 日志目录下7天前的日志并删除find $&#123;LOG_PATH&#125; -type f -name "*-$&#123;ACCESS_LOG&#125;" -mtime +7 -deletefind $&#123;LOG_PATH&#125; -type f -name "*-$&#123;ERROR_LOG&#125;" -mtime +7 -delete]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客美化添加live2d动画]]></title>
    <url>%2FHexo%E5%8D%9A%E5%AE%A2%E7%BE%8E%E5%8C%96%E6%B7%BB%E5%8A%A0live2d%E5%8A%A8%E7%94%BB%2F</url>
    <content type="text"><![CDATA[hexo-helper-live2d GitHub地址 安装插件 在hexo根目录执行 1npm install --save hexo-helper-live2d 选择动画模型 模型地址 live2d-widget-model-chitose live2d-widget-model-epsilon2_1 live2d-widget-model-gf live2d-widget-model-haru live2d-widget-model-haruto live2d-widget-model-hibiki live2d-widget-model-hijiki live2d-widget-model-izumi live2d-widget-model-koharu live2d-widget-model-miku live2d-widget-model-ni-j live2d-widget-model-nico live2d-widget-model-nietzsche live2d-widget-model-nipsilon live2d-widget-model-nito live2d-widget-model-shizuku live2d-widget-model-tororo live2d-widget-model-tsumiki live2d-widget-model-unitychan live2d-widget-model-wanko live2d-widget-model-z16 本次选择安装live2d-widget-model-haruto 1npm install live2d-widget-model-haruto 拷贝资源 在hexo根目录live2d_models 1mkdir -p live2d_models cp模型文件 1cp -r node_modules/live2d-widget-model-haruto/ live2d_models/ 编辑主配置编辑_config.yml 12345678910111213141516live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-haruto display: position: right width: 150 height: 300 mobile: show: true 重新部署1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 我部署到GitHub上的域名正常，服务器上的没生效，重启进程后生效。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Next主题增加动态背景并设置透明化]]></title>
    <url>%2FNext%E4%B8%BB%E9%A2%98%E5%A2%9E%E5%8A%A0%E5%8A%A8%E6%80%81%E8%83%8C%E6%99%AF%E5%B9%B6%E8%AE%BE%E7%BD%AE%E9%80%8F%E6%98%8E%E5%8C%96%2F</url>
    <content type="text"><![CDATA[编辑主题配置编辑 themes/next/_config.yml 12345678#canvas_nest: falsecanvas_nest: enable: true onmobile: true # display on mobile or not color: &apos;0,0,255&apos; # RGB values, use &apos;,&apos; to separate opacity: 0.5 # the opacity of line: 0~1 zIndex: -1 # z-index property of the background count: 99 # the number of lines 重新部署1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo-Next主题添加搜索功能]]></title>
    <url>%2FHexo-Next%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[安装插件博客根目录执行以下命令： 1npm install hexo-generator-searchdb --save 修改主配置编辑配置文件：_config.yaml 12345search: path: search.xml field: post format: html limit: 10000 修改主题配置编辑 themes/next/_config.yml 12local_search: enable: true 重新部署1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-HostAliases]]></title>
    <url>%2FKubernetes-HostAliases%2F</url>
    <content type="text"><![CDATA[https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/ k8s上微服务之间可以通过service的域名来互相访问。域名的解析是一般是通过在集群中的kube-dns来完成的。 如需向Pod的/etc/hosts文件添加条目实现解析需求时，可以使用Pod Spec中的HostAliases字段添加自定义条目。 例如： 123456789101112131415161718192021222324service/networking/hostaliases-pod.yaml apiVersion: v1kind: Podmetadata: name: hostaliases-podspec: restartPolicy: Never hostAliases: - ip: "127.0.0.1" hostnames: - "foo.local" - "bar.local" - ip: "10.1.2.3" hostnames: - "foo.remote" - "bar.remote" containers: - name: cat-hosts image: busybox command: - cat args: - "/etc/hosts" 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152apiVersion: apps/v1beta2kind: Deploymentmetadata: labels: app: vcg-gateway name: vcg-gateway namespace: defaultspec: replicas: 1 selector: matchLabels: app: vcg-gateway strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: labels: app: vcg-gateway spec: containers: - env: - name: aliyun_logs_vcg-gateway value: stdout image: &gt;- registry-vpc.cn-beijing.aliyuncs.com/vcg/vcg-gateway:pro-20190423162116 imagePullPolicy: Always name: vcg-gateway resources: limits: cpu: '1' memory: 4Gi requests: cpu: 500m memory: 1000Mi dnsPolicy: ClusterFirst hostAliases: - hostnames: - www.vcg.com ip: 39.97.197.135 - hostnames: - www1.visualchina.com - www1.vcg.com ip: 39.97.21.16 imagePullSecrets: - name: registry-vpc.cn-beijing.aliyuncs.com restartPolicy: Always schedulerName: default-scheduler securityContext: &#123;&#125; terminationGracePeriodSeconds: 30]]></content>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-Secrets]]></title>
    <url>%2FKubernetes-Secrets%2F</url>
    <content type="text"><![CDATA[背景信息若您需要在 Kubernetes 集群中使用一些敏感的配置，比如密码、证书等信息时，建议使用密钥（secret），即保密字典。 密钥有多种类型，例如： Service Account：用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的/run/secrets/kubernetes.io/serviceaccount目录中。 Opaque：base64 编码格式的 Secret，用来存储密码、证书等敏感信息。 Opaque 类型的数据是一个 map 类型，要求value 是 base64 编码格式 您也可通过命令行手动创建密钥，请参见 kubernetes secret 了解更多信息。 命令创建1234567891011kubectl create secretCreate a secret using specified subcommand.Available Commands: docker-registry Create a secret for use with a Docker registry generic Create a secret from a local file, directory or literal value tls Create a TLS secretUsage: kubectl create secret [flags] [options] 查看证书12345[cicd-jd@ops-jenkins-master ssl]$ kubectl get secretsNAME TYPE DATA AGEdefault-token-msfm9 kubernetes.io/service-account-token 3 24dregistry.cn-beijing.aliyuncs.com kubernetes.io/dockerconfigjson 1 24dveer-https kubernetes.io/tls 2 3h25m 123456789101112[cicd-jd@ops-jenkins-master ssl]$ kubectl describe secrets veer-httpsName: veer-httpsNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Type: kubernetes.io/tlsData====tls.crt: 3941 bytestls.key: 1676 bytes 删除1kubectl delete secret $NAME 示例创建SSL证书 准备公钥、私钥文件12[cicd-jd@ops-jenkins-master ssl]$ lsveer.key veer.pem 创建secret1kubectl create secret tls veer-https --cert=./veer.pem --key=./veer.key 验证123[cicd-jd@ops-jenkins-master ssl]$ kubectl get secrets veer-httpsNAME TYPE DATA AGEveer-https kubernetes.io/tls 2 3h22m]]></content>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx-ingress controller部署]]></title>
    <url>%2FNginx-ingress-controller%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[https://docs.jdcloud.com/cn/jcs-for-kubernetes/deploy-ingress-nginx-controller Ingress 是从Kubernetes集群外部访问集群内部服务的入口，概念示意可参考下方说明。你可以给Ingress配置提供外部可访问的URL、负载均衡、SSL、基于名称的虚拟主机等。用户通过POST Ingress资源到API server的方式来请求ingress。 12345internet |[ Ingress ]--|-----|--[ Services ] Ingress controller负责实现Ingress。Ingress controller在Kubernetes集群中默认不会自动启用，您可以在一个pod中部署任意类型的自定义Ingress Controller。本文将以Nginx-ingress controller为例，说明Controller部署和Ingress定义。更多外部类型的Ingresss Controller参考Kubernetes官方文档。 环境准备 从github下载nginx-ingress controller最新的安装部署文件,并将部署文件解压缩到本地目录：123wget https://github.com/nginxinc/kubernetes-ingress/archive/v1.4.5.tar.gztar -zxvf v1.4.5.tar.gz 说明：本文说明在1.12.3版本的集群上如何部署nginx-ingress controller，如集群版本不同，选择其他适合的ginx-ingress controller安装部署文件。 进入解压缩后的nginx-ingress controller安装目录；1cd kubernetes-ingress-1.4.5/deployments 安装nginx-ingress controller 为nginx-ingress controller创建一个namespace和service account：1kubectl apply -f common/ns-and-sa.yaml 为NGINX默认Server配置TLS证书和key，并将TLS证书和key保存到secret中：1kubectl apply -f common/default-server-secret.yaml 说明：建议使用合适的TLS证书和key替换default-server-secret.yaml文件中自签发的证书和key。 创建config map保存NGINX的自定义配置：1kubectl apply -f common/nginx-config.yaml 说明：目前提供的config map中的data为空，您可以按需添加自定义配置。 为第1步中创建的service account配置RBAC：1kubectl apply -f rbac/rbac.yaml 以Deployment的方式部署nginx-ingress controller:1kubectl apply -f deployment/nginx-ingress.yaml 执行如下命令，确定部署nginx-ingress controller的Deployment运行正常：1234 kubectl get deployment -n nginx-ingress NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-ingress 1 1 1 1 24d 创建ingress的LoadBalance在 Kubernetes集群中，每个Pod都具有唯一的内部 IP 地址，但是Deployment中的Pod随时可能被删除或创建，导致Pod IP地址不断变化。因此需要创建一个Service对外暴露Pod中的应用。Service具有唯一的固定IP地址且能够为后端添加的成员Pod提供负载均衡。在京东云Kubernetes集群中您可以使用LoadBalance类型的Service，为Service关联创建一个应用负载均衡，并通过负载均衡绑定的公网IP，将Service后端关联的nginx-ingress controller应用暴露到公网： 123456789101112131415161718apiVersion: v1kind: Servicemetadata: name: nginx-ingress #建议Service使用与nginx-ingress controller对应的Deployment名称相同的名称 namespace: nginx-ingressspec: type: LoadBalancer ports: - port: 80 targetPort: 80 protocol: TCP name: http - port: 443 targetPort: 443 protocol: TCP name: https selector: app: nginx-ingress 说明：本例使用80和443端口绑定nginx-ingress controller应用 将上述Service定义到ingress.yaml文件，执行如下命令创建对应的Service： 1kubectl create -f ingress.yaml 获取公网IP等待一段时间，确定Service已经配置完成，并获取Service上配置的External IP字段 1234kubectl get svc -n nginx-ingressNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEnginx-ingress LoadBalancer 192.168.58.218 114.67.80.218 80:32436/TCP,443:30110/TCP 3h13m 说明：Service的External IP将作为nginx-ingress controller的VIP，为集群中使用nginx-ingress controller的Ingress提供公网访问入口 关联的External IP作为公网入口IP最后，在Ingress controller的Deployment部署文件nginx-ingress.yaml中增加一对环境变量”-args -external-service=nginx-ingress”,配置Ingress controller使用Service名称关联的External IP作为公网入口IP： 1234args: - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret - -external-service=nginx-ingress #新增内容 1kubectl apply -f deployment/nginx-ingress.yaml #重新部署nginx-ingress controller 验证Pod执行如下命令确定nginx-ingress controller相关的Pod运行正常，即可完成nginx ingress controller部署： 12345kubectl get pod -n nginx-ingressNAME READY STATUS RESTARTS AGEnginx-ingress-f67b87b88-5cspd 1/1 Running 0 3h11mnginx-ingress-f67b87b88-n7qnw 1/1 Running 0 3h13m 示例应用例如：配置www2.veer.com的ingress配置 123456789101112131415161718apiVersion: extensions/v1beta1kind: Ingressmetadata: name: cms-veer # 变量：名字 namespace: defaultspec: rules: - host: www2.veer.com # 变量：url http: paths: - backend: serviceName: node-vcg-veer-pre # 变量：后端应用service servicePort: 80 # 变量：后端应用service端口 path: / tls: - hosts: - www2.veer.com secretName: veer-https # 变量：ssl证书]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>Ingress</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Confluence安装-维护-迁移实践]]></title>
    <url>%2FConfluence%E5%AE%89%E8%A3%85-%E7%BB%B4%E6%8A%A4-%E8%BF%81%E7%A7%BB%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[Confluence介绍 Confluence是由澳大利亚软件公司Atlassian开发和发布的协作软件程序 Confluence是一个专业的企业知识管理与协同软件，也可以用于构建企业wiki。使用简单，但它强大的编辑和站点管理特征能够帮助团队成员之间共享信息、文档协作、集体讨论，信息推送。 Confluence为团队提供一个协作环境。在这里，团队成员齐心协力，各擅其能，协同地编写文档和管理项目。从此打破不同团队、不同部门以及个人之间信息孤岛的僵局，Confluence真正实现了组织资源共享。 安装 https://confluence.atlassian.com/conf612/installing-confluence-on-linux-from-archive-file-958778538.html 下载安装包Download the tar.gz file for your operating system - https://www.atlassian.com/software/confluence/download. 本次演示我下载的文件包为：atlassian-confluence-6.12.0.zip 安装jdk环境12yum install -y java-1.8.0-openjdk.x86_64java -version # 验证 创建Confluence用户1useradd -create-home --comment "Account for running Confluence" --shell /bin/bash confluence 解压安装包、创建配置、配置权限目录规划： ​ 安装目录：/data/vcg/confluence ​ 数据目录：/data/vcg/confluence-home 1cp /root/atlassian-confluence-6.12.0.zip /data/vcg/ 1yum install unzip -y 123cd /data/vcg/unzip atlassian-confluence-6.12.0.zipmv atlassian-confluence-6.12.0 confluence 1mkdir -p /data/vcg/confluence-home 1234chown -R confluence /data/vcg/confluence/chmod -R u=rwx,go-rwx /data/vcg/confluence/chown -R confluence /data/vcg/confluence-home/chmod -R u=rwx,go-rwx /data/vcg/confluence-home/ 数据库vcg这边使用的阿里云RDS数据库，未手动安装MySQL 数据库使用MySQL，需安装驱动软件。获取mysql-connector-java的安装包 1cp mysql-connector-java-5.1.45-bin.jar /data/vcg/confluence/confluence/WEB-INF/lib/ 配置1echo "confluence.home=/data/vcg/confluence-home/" &gt; confluence/confluence/WEB-INF/classes/confluence-init.properties 12 页面配置1浏览器访问ip:8090 继续配置Confluence 迁移备份数据登录老Confluence界面，进入”站点管理”—“备份已还原”，点击”备份”，如图 数据备份路径为：/data/vcg/confluence-home/backups/ 拷贝备份数据包到新服务器备份必须复制至/data/vcg/confluence-home/restore目录中。 1scp /data/vcg/confluence-home/backups/xmlexport-20190225-205713-119.zip root@'xxxx':/data/vcg/confluence-home/restore/ 部署新的Confluence备份恢复登录新的Confluence的”站点管理”—“备份已还原”。 维护备份数据定期删除12crontab -e0 15 * * * find /data/vcg/confluence-home/backups/* -type f -mtime +5 -exec rm &#123;&#125; \; 漏洞补丁(被植入挖矿程序) https://help.aliyun.com/noticelist/articleid/1000128459.html?spm=a2c4g.789213612.n2.10.2a716141mqqJjY 解决办法：升级Widget Connector 组件 培训文档]]></content>
      <tags>
        <tag>Confluence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次Java微服务容器化维护工作]]></title>
    <url>%2F%E8%AE%B0%E4%B8%80%E6%AC%A1Java%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%B9%E5%99%A8%E5%8C%96%E7%BB%B4%E6%8A%A4%E5%B7%A5%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[事件背景 容器架构由Swarm迁移到Kubernetes Swarm集群中服务发现、服务注册使用Consul，迁移到K8s后注册发现是的K8s的kube-dns基础组件实现。 utilservice-vcg-com这个微服务部署在两台ecs上，java -jar 启动后 手动注册到consul中，这样实现Swarm集群中的应用可以通过Consul访问util服务。 思路 与相关研发沟通，确定utilservice程序一些基础信息：比如 ​ 需要哪些基础组件，在ecs上部署遇到什么问题，如何处理的 ​ git仓库地址、服务启动命令、服务端口、是否连接数据库、服务调用关系。 确定使用jdk环境，需要使用到 wkhtmltopdf 这个命令，用于生成pdf； 生成的pdf过程会有 字体和语言的问题，需提前处理。 操作 确定基础镜像访问https://hub.docker.com，搜索 wkhtmltopdf 关键词 确定基础镜像使用 buildo/java8-wkhtmltopdf 。 Dockerfile (第一版)1FROM buildo/java8-wkhtmltopdf 下载JCE需要使用到JCE，在oracle官网下载。 JDK7的下载地址: http://www.oracle.com/technetwork/java/javase/downloads/jce-7-download-432124.htmlJDK8的下载地址: http://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html Java Cryptography Extension (JCE) 无限强度权限策略文件 8 下载 Dockerfile (第二版)12345678FROM buildo/java8-wkhtmltopdfMAINTAINER hongye.zhao@vcg.comRUN mkdir -p /application/WORKDIR /application/ADD . .RUN unzip jce_policy-8.zip &amp;&amp; \ cp UnlimitedJCEPolicyJDK8/US_export_policy.jar /docker-java-home/jre/lib/security &amp;&amp; \ cp UnlimitedJCEPolicyJDK8/local_policy.jar /docker-java-home/jre/lib/security &amp;&amp; \ 处理程序报错1、找到不到 iSignature.pfx 证书：报错截图： 可以看到找不到/media/providerstamp/signature/iSignature.pfx 证书文件，简单，从老服务器上找到对应文件，拷贝过来。 Dockerfile (第三版)12345678910FROM buildo/java8-wkhtmltopdfMAINTAINER hongye.zhao@vcg.comRUN mkdir -p /application/WORKDIR /application/ADD . .RUN unzip jce_policy-8.zip &amp;&amp; \ cp UnlimitedJCEPolicyJDK8/US_export_policy.jar /docker-java-home/jre/lib/security &amp;&amp; \ cp UnlimitedJCEPolicyJDK8/local_policy.jar /docker-java-home/jre/lib/security &amp;&amp; \ mkdir -p /media/providerstamp/signature/ &amp;&amp; \ cp iSignature.pfx /media/providerstamp/signature/ &amp;&amp; \ 2、tmpDic不是文件夹 研发查看代码后确定是要使用 /media/providerstamp/temp/ 目录，索性登录老服务器上查看/media/providerstamp下所有目录，都创建好，并将需要的文件scp拷贝过来。 看到还有 done 、unitrust目录，并且unitrust目录中的unitrust.key 程序也会用到。 Dockerfile (第四版)1234567891011121314FROM buildo/java8-wkhtmltopdfMAINTAINER hongye.zhao@vcg.comRUN mkdir -p /application/WORKDIR /application/ADD . .RUN unzip jce_policy-8.zip &amp;&amp; \ cp UnlimitedJCEPolicyJDK8/US_export_policy.jar /docker-java-home/jre/lib/security &amp;&amp; \ cp UnlimitedJCEPolicyJDK8/local_policy.jar /docker-java-home/jre/lib/security &amp;&amp; \ mkdir -p /media/providerstamp/signature/ &amp;&amp; \ mkdir -p /media/providerstamp/done/ &amp;&amp; \ mkdir -p /media/providerstamp/unitrust/ &amp;&amp; \ mkdir -p /media/providerstamp/temp/ &amp;&amp; \ cp unitrust.key /media/providerstamp/unitrust &amp;&amp; \ cp iSignature.pfx /media/providerstamp/signature/ &amp;&amp; \ 3、pdf内容乱码乱码是由于字体问题，简单直接，直接从老服务器上拷贝 /usr/share/fonts 目录。 Dockerfile (第五版)12345678910111213141516171819FROM buildo/java8-wkhtmltopdfMAINTAINER hongye.zhao@vcg.comRUN mkdir -p /application/WORKDIR /application/ADD . .RUN unzip jce_policy-8.zip &amp;&amp; \ cp UnlimitedJCEPolicyJDK8/US_export_policy.jar /docker-java-home/jre/lib/security &amp;&amp; \ cp UnlimitedJCEPolicyJDK8/local_policy.jar /docker-java-home/jre/lib/security &amp;&amp; \ mkdir -p /media/providerstamp/signature/ &amp;&amp; \ mkdir -p /media/providerstamp/done/ &amp;&amp; \ mkdir -p /media/providerstamp/unitrust/ &amp;&amp; \ mkdir -p /media/providerstamp/temp/ &amp;&amp; \ cp unitrust.key /media/providerstamp/unitrust &amp;&amp; \ cp iSignature.pfx /media/providerstamp/signature/ &amp;&amp; \ rm -f /usr/local/bin/wkhtmltopdf &amp;&amp; \ rm -rf /usr/share/fonts &amp;&amp; \ cp wkhtmltopdf /usr/local/bin/ &amp;&amp; \ tar zxf fonts.tar.gz &amp;&amp; \ mv fonts/ /usr/share/ 至此，此微服务容器化已完成。👏👏👏]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-镜像image]]></title>
    <url>%2FDocker-%E9%95%9C%E5%83%8Fimage%2F</url>
    <content type="text"><![CDATA[Docker镜像是启动容器的基石。 什么是Docker镜像 Docker镜像是由文件系统叠加而成。最底端是一个文件引导系统，即bootfs。Docker用户不会与引导文件系统有直接的交互。Docker镜像的第二层是root文件系统rootfs，通常是一种或多种操作系统，例如ubuntu等。在Docker中，文件系统永远都是只读的，在每次修改时，都是进行拷贝叠加从而形成最终的文件系统。Docker称这样的文件为镜像。一个镜像可以迭代在另一个镜像的顶部。位于下方的镜像称之为父镜像，最底层的镜像称之为基础镜像。最后，当从一个镜像启动容器时，Docker会在最顶层加载一个读写文件系统作为容器。 Docker的这种机制我们称之为写时复制。 查看镜像列表 1docker images 该命令可以用于查找当前系统中所有存在的镜像列表。 Ps：本地镜像默认保存在Docker宿主机的/var/lib/docker目录下。所有的镜像都是保存在仓库中，而仓库位于Registry中。默认的Registry是Docker公司运营的Docker Hub。每个镜像仓库都可以存放很多的镜像。 拉取镜像 1docker pull centos 上述命令会拉取镜像到本地。 为了区分同一个仓库中不同的镜像，Docker提供了一种tag的功能。我们可以给每个版本的镜像添加一个唯一的tag来标识该镜像。此时，镜像的名称如下：仓库名称:tag。我们在运行镜像或拉取镜像时，可以直接指定对应的标签。 1docker pull registry-vpc.cn-beijing.aliyuncs.com/vcgcs/jdk8:util 查找镜像 从Docker Hub查找有哪些公共的可用镜像 1docker search keywords 构建Docker镜像 docker build 命令用于使用 Dockerfile 创建镜像。 1docker build -t runoob/ubuntu:v1 . 使用URL github.com/creack/docker-firefox 的 Dockerfile 创建镜像。 1docker build github.com/creack/docker-firefox 也可以通过 -f Dockerfile 文件的位置： 1docker build -f /path/to/a/Dockerfile . 登录镜像仓库使用阿里云容器镜像服务 1docker login --username="ops@vcg.com" --password="******" registry-vpc.cn-beijing.aliyuncs.com 推送镜像到仓库1docker push registry-vpc.cn-beijing.aliyuncs.com/vcgcs/jdk8:util 修改镜像Tag12docker images # 获取ImageIddocker tag [ImageId] registry.cn-beijing.aliyuncs.com/vcg/500px-vcg-com:[镜像版本号]]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-批量修改密码]]></title>
    <url>%2FAnsible-%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[介绍使用ansible批量修改用户密码的方法，因为在使用ansible修改用户密码的时候不能使用明文的方式，需要先加密，所以就需要使用一个方法对输入的明文的密码进行加密，下面就直接上干货。 更改多个固定域名1cat changePasswd.yaml 12345678---- hosts: ops gather_facts: false tasks: - name: change user passwd user: name=&#123;&#123; item.name &#125;&#125; password=&#123;&#123; item.chpass | password_hash('sha512') &#125;&#125; update_password=always with_items: - &#123; name: 'root', chpass: '***********' &#125; 1ansible-playbook changePasswd.yaml]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云WAF + Kubernetes Ingress 架构下无法拿到客户端真实IP的问题处理]]></title>
    <url>%2F%E9%98%BF%E9%87%8C%E4%BA%91WAF-Kubernetes-Ingress-%E6%9E%B6%E6%9E%84%E4%B8%8B%E6%97%A0%E6%B3%95%E6%8B%BF%E5%88%B0%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9C%9F%E5%AE%9EIP%E7%9A%84%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[背景:2019年04月19日晚21:10分进行网络维护，内容如下： ​ 将域名CNAME到阿里云的Web防火墙（以下简称为WAF），业务请求经防火墙解析到Kubernetes 的 Ingress 的负载均衡（SLB）地址 故障现象：​ 后端应用通过获取请求中的X-Forwarded-For字段，拿到的IP地址为WAF回源地址，非客户端真实IP。 排查记录: 21:15 查看Ingress日志，发现Ingress拿到的IP就是WAF回源地址，为错误IP，确定非前端nodejs代码bug。 21:33 联系阿里云技术团队一起排查问题。 22:20 确认Ingress的模板文件中 the_real_ip 变量是拿的 remote_addr 字段，等待阿里技术联系Ingree研发同学，给出回复。 23:23 Ingree研发同学联系上后确认Ingress没问题，可能是WAF没传真实IP到Ingress。 23:50 在Ingress容器和前端nodejs所在宿主机tcpdump工具抓包后分析得出： (1)、WAF已经将真实客户端地址放到了 x-Forwarded-For 的字段中传给了ECS(2)、ECS(容器的ingress)将真实的客户端IP，放到了x-Original-Forwarded-For；而将WAF的回源地址放到了 x-Forwarded-For 4月20日 00:29 将compute-full-forwarded-for配置到Ingress的ConfigMap中，问题解决。 操作：1kubectl -n kube-system edit cm nginx-configuration 1234在data标签下添加如下：compute-full-forwarded-for: &quot;true&quot;forwarded-for-header: &quot;X-Forwarded-For&quot;use-forwarded-headers: &quot;true&quot; 结论：阿里云容器服务Kubernetes集群的Ingress默认ConfigMap中未配置 compute-full-forwarded-for参数，导致将ingress拿到的WAF回源IP替换为XFF，而非附加到XFF中。 https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#compute-full-forwarded-for 反思： 预览环境和线上环境架构不一致： 此次故障中，预览环境未使用WAF防护，直接解析到K8S集群，未提前发现此次问题，已修正，以后尽量维持环境统一，避免此类问题出现。 故障点定位速度慢： 网络请求问题优先抓包分析，提升故障定位速度，后续夯实基础知识，提升问题排查能力。 Kubernetes专业知识掌握程度较低 目前仅仅在使用层面上能力ok，但是其实现原理、组件实现方式等知识点薄弱，后续还需在K8S学习中多总结，多学习，争取减少故障，提升运维能力。]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-kubectl]]></title>
    <url>%2FKubernetes-kubectl%2F</url>
    <content type="text"><![CDATA[管理Kubernetes集群的工具 安装 下载最新版的kubectl客户端https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG.md&gt; 安装和配置https://kubernetes.io/docs/tasks/tools/install-kubectl/&gt; 验证安装 1kuberctl version 配置集群凭证您可以使用scp命令安全地将主节点的配置从 Kubernetes 集群主 VM 中的 /etc/kubernetes/kube.conf 复制到本地计算机的 $HOME/.kube/config（kubectl 预期凭据所在的位置）。 12mkdir $HOME/.kubescp root@&lt;master-public-ip&gt;:/etc/kubernetes/kube.conf $HOME/.kube/config 公有云环境也可以在集群配置页面获取到config配置 验证连接 1kubect get all 命令参数help-获取帮助信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475zhaohongye ~ ^-^ #kubectl helpkubectl controls the Kubernetes cluster manager.Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/Basic Commands (Beginner): create Create a resource from a file or from stdin. expose 使用 replication controller, service, deployment 或者 pod并暴露它作为一个 新的 Kubernetes Service run 在集群中运行一个指定的镜像 set 为 objects 设置一个指定的特征 run-container 在集群中运行一个指定的镜像. This command isdeprecated, use "run" insteadBasic Commands (Intermediate): get 显示一个或更多 resources explain 查看资源的文档 edit 在服务器上编辑一个资源 delete Delete resources by filenames, stdin, resources and names, orby resources and label selectorDeploy Commands: rollout Manage the rollout of a resource rolling-update 完成指定的 ReplicationController 的滚动升级 scale 为 Deployment, ReplicaSet, Replication Controller 或者 Job设置一个新的副本数量 autoscale 自动调整一个 Deployment, ReplicaSet, 或者ReplicationController 的副本数量Cluster Management Commands: certificate 修改 certificate 资源. cluster-info 显示集群信息 top Display Resource (CPU/Memory/Storage) usage. cordon 标记 node 为 unschedulable uncordon 标记 node 为 schedulable drain Drain node in preparation for maintenance taint 更新一个或者多个 node 上的 taintsTroubleshooting and Debugging Commands: describe 显示一个指定 resource 或者 group 的 resources 详情 logs 输出容器在 pod 中的日志 attach Attach 到一个运行中的 container exec 在一个 container 中执行一个命令 port-forward Forward one or more local ports to a pod proxy 运行一个 proxy 到 Kubernetes API server cp 复制 files 和 directories 到 containers和从容器中复制 files 和 directories. auth Inspect authorizationAdvanced Commands: apply 通过文件名或标准输入流(stdin)对资源进行配置 patch 使用 strategic merge patch 更新一个资源的 field(s) replace 通过 filename 或者 stdin替换一个资源 convert 在不同的 API versions 转换配置文件Settings Commands: label 更新在这个资源上的 labels annotate 更新一个资源的注解 completion Output shell completion code for the specified shell (bash orzsh)Other Commands: api-versions Print the supported API versions on the server, in the form of"group/version" config 修改 kubeconfig 文件 help Help about any command plugin Runs a command-line plugin version 输出 client 和 server 的版本信息Usage: kubectl [flags] [options]Use "kubectl &lt;command&gt; --help" for more information about a given command.Use "kubectl options" for a list of global command-line options (applies to allcommands). get-获取信息Display one or many resources 123456789101112131415161718192021222324252627Examples: # List all pods in ps output format. kubectl get pods # List all pods in ps output format with more information (such as node name). kubectl get pods -o wide # List a single replication controller with specified NAME in ps output format. kubectl get replicationcontroller web # List a single pod in JSON output format. kubectl get -o json pod web-pod-13je7 # List a pod identified by type and name specified in "pod.yaml" in JSON output format. kubectl get -f pod.yaml -o json # Return only the phase value of the specified pod. kubectl get -o template pod/web-pod-13je7 --template=&#123;&#123;.status.phase&#125;&#125; # List all replication controllers and services together in ps output format. kubectl get rc,services # List one or more resources by their type and names. kubectl get rc/web service/frontend pods/web-pod-13je7 # List all resources with different types. kubectl get all scale-扩缩容Set a new size for a Deployment, ReplicaSet, Replication Controller, or StatefulSet. 123456789101112131415161718Examples: # Scale a replicaset named &apos;foo&apos; to 3. kubectl scale --replicas=3 rs/foo # Scale a resource identified by type and name specified in &quot;foo.yaml&quot; to 3. kubectl scale --replicas=3 -f foo.yaml # If the deployment named mysql&apos;s current size is 2, scale mysql to 3. kubectl scale --current-replicas=2 --replicas=3 deployment/mysql # Scale multiple replication controllers. kubectl scale --replicas=5 rc/foo rc/bar rc/baz # Scale statefulset named &apos;web&apos; to 3. kubectl scale --replicas=3 statefulset/web kubectl scale Deployment node-vcg-web --replicas=1 kubectl scale Deployment node-vcg-web --replicas=10 批量扩缩容 123for i in `kubectl get deployment | awk '&#123;print $1&#125;' |grep -v NAME`; do kubectl scale Deployment $i --replicas=1done exec-在container中执行命令Execute a command in a container. 123456789Options: -c, --container='': Container name. If omitted, the first container in the pod will be chosen -p, --pod='': Pod name -i, --stdin=false: Pass stdin to the container -t, --tty=false: Stdin is a TTYExamples: kubectl exec 123456-7890 -c ruby-container -it -- bash -ilUsage: kubectl exec POD [-c CONTAINER] -- COMMAND [args...] [options]]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo-博客中添加图片等资源]]></title>
    <url>%2FHexo-%E5%8D%9A%E5%AE%A2%E4%B8%AD%E6%B7%BB%E5%8A%A0%E5%9B%BE%E7%89%87%E7%AD%89%E8%B5%84%E6%BA%90%2F</url>
    <content type="text"><![CDATA[引用于 https://blog.csdn.net/qq_40265501/article/details/80019774 官方介绍：https://hexo.io/zh-cn/docs/asset-folders.html 一图胜万言 博客中有时候图片比文字更有说服力，比如：代码运行结果，代码运行效果等 开启’资源文件管理’功能将 config.yml文件中的 post_asset_folder 选项设为 true 12_config.ymlpost_asset_folder: true 安装Hexo插件插件地址：https://github.com/dangxuandev/hexo-asset-image 1npm install hexo-asset-image --save 在博客中添加图片 新建博客 1hexo n test 查看目录结构 123[root@nginx GeekSRE]# ls -l source/_posts/ |grep testdrwxr-xr-x 2 root root 4096 4月 17 17:29 test-rw-r--r-- 1 root root 96 4月 17 17:35 test.md 可以看到 会在 source/_posts 目录创建 test.md 和 test目录 与博客同名目录用于存放资源文件，如图片、CSS、JS 文件等 上传图片到”文章资源文件夹” 123# 比如使用CSDN博客中的图片：cd source/_posts/testwget https://img-blog.csdn.net/20180420154609543 引用 12345vim source/_posts/test.md# ![你想要输入的替代文字](图片文件)# 比如：![图片](test.jpg) 保存 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 验证效果]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab代码托管]]></title>
    <url>%2FGitLab%E4%BB%A3%E7%A0%81%E6%89%98%E7%AE%A1%2F</url>
    <content type="text"><![CDATA[GitLab 是一个用于仓库管理系统的开源项目，使用Git作为代码管理工具，并在此基础上搭建起来的web服务。 官网：https://about.gitlab.com/stages-devops-lifecycle/ 安装配置Yum源123456vim /etc/yum.repos.d/gitlab_gitlab-ee.repo[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1 安装12yum install -y postfixyum install gitlab-ce -y 配置配置文件：/etc/gitlab/gitlab.rb (建议每次修改前备份此文件) 1234567891011121314151617181920212223242526272829 external_url 'https://git.visualchina.com' # 域名配置 gitlab_rails['time_zone'] = 'Asia/Shanghai' # 时区 nginx['redirect_http_to_https'] = true # SSL证书 nginx['ssl_certificate'] = "/data/vcg/ssl/visualchina.pem" nginx['ssl_certificate_key'] = "/data/vcg/ssl/visualchina.key" gitlab_rails['ldap_enabled'] = truegitlab_rails['ldap_servers'] = YAML.load &lt;&lt;-'EOS' # remember to close this block with 'EOS' below main: # 'main' is the GitLab 'provider ID' of this LDAP server label: 'LDAP' host: '172.16.239.3' port: 389 uid: 'cn' method: 'plain' # "tls" or "ssl" or "plain" bind_dn: 'cn=root,dc=vcg,dc=com' password: 'vcg@2018' active_directory: true allow_username_or_email_login: false block_auto_created_users: false base: 'ou=People,dc=vcg,dc=com' user_filter: '' attributes: username: ['cn'] email: ['mail'] name: 'cn' first_name: 'givenName' last_name: 'sn'EOS 配置完成后进行配置更新1gitlab-ctl reconfigure 检查是否配置成功1gitlab-rake gitlab:ldap:check（列出前100个用户） 重启gitlab服务1gitlab-ctl restart 访问访问ip:80端口 配置root密码，至此部署完成。 升级升级规范和建议https://docs.gitlab.com/ee/policy/maintenance.html#upgrade-recommendations 首先升级到主要版本中的最新可用次要版本 例如：8.13.4 升级到 11.3.4 ，升级路径为 8.13.4 -&gt; 8.17.7 -&gt; 9.5.10 -&gt; 10.8.7 -&gt; 11.3.4 ​ 即：8.17.7是版本8中的最后一个版本, 9.5.10是版本9中的最后一个版本, 10.8.7是版本10中的最后一个版本 升级操作本次升级版本为 10.7.0 ，升级到最新版本 11.9.8 ，注：2019年04月16日 1、下载10.8.7版本的rpm包1wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-10.8.7-ce.0.el7.x86_64.rpm 2、安装升级到10.8.7版本1rpm -Uvh gitlab-ce-10.8.7-ce.0.el7.x86_64.rpm 3、再升级到11.9.8版本1yum install gitlab-ce.x86_64 迁移备份源GitLab数据12345gitlab-rake gitlab:backup:create RAILS_ENV=production# Creating backup archive: 1555983152_2019_04_23_11.9.8_gitlab_backup.tar ...# 数据保存在 /var/opt/gitlab/backups，自动生成文件名，比如本次的 1555983152_2019_04_23_11.9.8_gitlab_backup.tar SCP迁移数据12#按需替换目标地址scp /var/opt/gitlab/backups/1555983152_2019_04_23_11.9.8_gitlab_backup.tar root@1.1.1.1:/root/var/opt/gitlab/backups 安装GitLab请参考 安装 章节 恢复数据12gitlab-rake gitlab:backup:restore RAILS_ENV=production BACKUP=1555983152_2019_04_23_11.9.8# BACKUP的时间点必须与原服务器备份后的文件名一致 维护定期备份1234crontab -l0 14 * * * /usr/bin/gitlab-rake gitlab:backup:create0 15 * * * find /var/opt/gitlab/backups/* -type f -mtime +3 -exec rm &#123;&#125; \; gitlab-ctl命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869[root@iZ2ze4cng635a2k047qus5Z ~]# gitlab-ctl --helpomnibus-ctl: command (subcommand)check-config Check if there are any configuration in gitlab.rb that is removed in specified versiondeploy-page Put up the deploy pagediff-config Compare the user configuration with package available configurationprometheus-upgrade Upgrade the Prometheus data to the latest supported versionremove-accounts Delete *all* users and groups used by this packageupgrade Run migrations after a package upgradeGeneral Commands: cleanse Delete *all* gitlab data, and start from scratch. help Print this help message. reconfigure Reconfigure the application. show-config Show the configuration that would be generated by reconfigure. uninstall Kill all processes and uninstall the process supervisor (data will be preserved).Service Management Commands: graceful-kill Attempt a graceful stop, then SIGKILL the entire process group. hup Send the services a HUP. int Send the services an INT. kill Send the services a KILL. once Start the services if they are down. Do not restart them if they stop. restart Stop the services if they are running, then start them again. service-list List all the services (enabled services appear with a *.) start Start services if they are down, and restart them if they stop. status Show the status of all the services. stop Stop the services, and do not restart them. tail Watch the service logs of all enabled services. term Send the services a TERM. usr1 Send the services a USR1. usr2 Send the services a USR2.Container Registry Commands: registry-garbage-collect Run Container Registry garbage collection.Database Commands: pg-password-md5 Generate MD5 Hash of user password in PostgreSQL format pg-upgrade Upgrade the PostgreSQL DB to the latest supported version revert-pg-upgrade Run this to revert to the previous version of the database set-replication-password Set database replication passwordLet's Encrypt Commands: renew-le-certs Renew the existing Let's Encrypt certificates]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[域名SSL证书]]></title>
    <url>%2F%E5%9F%9F%E5%90%8DSSL%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[SSL证书 什么是数字证书？ 数字证书是一个经权威授权机构数字签名、包含公开密钥拥有者信息以及公开密钥的文件，是权威机构颁发给网站的可信凭证。最简单的证书包含一个公开密钥、证书名称以及证书授权中心的数字签名。 数字证书还有一个重要的特征：只在特定的时间段内有效。 什么是SSL？ SSL协议是一种可实现网络通信加密的安全协议，可在浏览器和网站之间建立加密通道，保障数据在传输的过程中不被篡改或窃取。 什么是SSL证书？ SSL证书采用SSL协议进行通信，是由权威机构颁发给网站的可信凭证。 SSL证书采用SSL协议进行通信。SSL证书部署到Web服务器后，Web服务器访问将启用HTTPS协议。您的网站将会通过 HTTPS 加密协议来传输数据，可帮助Web服务器和网站间建立可信的加密链接，从而保证网络数据传输的安全。 什么是HTTPS？ HTTPS是一种基于SSL协议的网站加密传输协议。 网站安装SSL证书后，使用HTTPS加密协议访问，可激活客户端浏览器到网站服务器之间的SSL加密通道（SSL协议），从而实现高强度双向加密传输，防止传输数据被泄露或篡改。HTTPS 也就是HTTP + SSL，是HTTP的安全版。 什么是CA认证中心？ CA认证中心（CA机构），即证书授权中心（Certificate Authority），或称证书授权机构。 CA认证中心作为电子商务交易中受信任的第三方，承担公钥体系中公钥合法性检验的责任。 SSL证书类型配置表证书根据不同的验证级别，分为以下三类： 域名型SSL（DV SSL） 企业型SSL（OV SSL） 增强型SSL（EV SSL） 根据保护域名的数量需求，SSL 证书又分为： 单域名版：只保护一个域名，例如 www.abc.com 或者 login.abc.com 之类的单个域名 多域名版：一张证书可以保护多个域名，例如同时保护 www.abc.com , www.bcd.com, pay.efg.com 等 通配符版：一张证书保护同一个主域名下同一级的所有子域名，不限个数，形如 *.abc.com 。注意，通配符版只有 DVSSL 和 OVSSL 具有， EVSSL 不具有通配符版本。 证书品牌 证书类型 保护域名的类型 说明 GeoTrust 专业版OV SSL 1个带通配符的域名1个明细域名多个明细域名 提供加密功能，对申请者的身份进行严格的审核验证，可提供可信身份证明。多个域名例上限为300个。如: buy1.example.com, buy2.example.com, next.buy.example2.com, 上述3个明细子域名计算为3个域名。 高级版EV SSL 1个域名多个域名 提供加密功能，对申请者做最严格的身份审核验证，提供最高度可信身份证明，提供浏览器绿色地址栏。 GlobalSign 专业版OV SSL 通配符域名 提供加密功能，对申请者进行严格的身份审核验证，提供可信身份证明。 CFCA 专业版OV SSL 通配符域名1个域名多个域名 提供加密功能，对申请者进行严格的身份审核验证，提供可信身份证明。 高级版EV SSL 1个域名多个域名 提供加密功能，对申请者做最严格的身份审核验证，提供最高度可信身份证明，提供浏览器绿色地址栏。 Symantec 专业版OV SSL 通配符域名1个域名多个域名 提供加密功能，对申请者进行严格的身份审核验证，提供可信身份证明。 通配符DV SSL 通配符域名 增强型OV SSL 1个域名多个域名 提供站点加密功能，需要核验组织注册信息，证书中会显示组织名称。组织信息验证通过后，3个工作日内颁发证书。 高级版EV SSL 1个域名多个域名 提供加密功能，对申请者做最严格的身份审核验证，提供最高度可信身份证明，提供浏览器绿色地址栏。 增强型EV SSL 1个域名多个域名 增强型EV SSL提供站点加密功能，浏览器绿色地址栏显示组织信息强化信任。组织信息验证通过后7个工作日内颁发证书。 免费型DV SSL 1个域名 免费新根证书，切入DigiCert PKI体系，兼容性操作系统版本IOS 5.0+、Android 2.3.3+、JRE 1.6.5+、WIN 7+。最多保护一个明细子域名，不支持通配符，一个阿里云帐户最多签发20张免费证书。 SSL证书购买登录阿里云控制台，进入SSL证书服务。 SSL证书更新公司域名SSL证书即将到期，替换SSL证书需知道哪些二级域名使用了HTTPS访问，并且获取SSL证书过期时间，来验证证书是否更新。 获取域名下的解析信息登录域名服务商控制条—云解析—域名解析列表—导出解析记录 将二级域名的记录写入domains.txt文件备用 编写脚本1234567891011#!/bin/bashfor domain in `cat domains.txt` #读取存储了需要监测的域名的文件do curl $domain.vcg.com:443 1&gt;/dev/null 2&gt;/dev/null --connect-timeout 3 if [[ $? -eq 0 ]]; then END_TIME=$(echo | openssl s_client -servername $domain.vcg.com -connect $domain.vcg.com:443 2&gt;/dev/null | openssl x509 -noout -dates |grep 'After'| awk -F '=' '&#123;print $2&#125;'| awk -F ' +' '&#123;print $1,$2,$4 &#125;' ) echo "$domain.vcg.com 的SSL证书到期时间为 $END_TIME " &gt;&gt; result1.txt else echo "$domain.vcg.com 没https " &gt;&gt; result1.txt fidone 根据输出文件查看SSL证书过期时间，进行证书替换工作SSL证书更新的配置路径 阿里云OSS-对象存储 阿里云WAF-Web防火墙 阿里云SLB-负载均衡 Nginx #####]]></content>
      <categories>
        <category>Linux</category>
        <category>SSL证书</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>SSL证书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[暴力破解攻击和防御]]></title>
    <url>%2F%E6%9A%B4%E5%8A%9B%E7%A0%B4%E8%A7%A3%E6%94%BB%E5%87%BB%E5%92%8C%E9%98%B2%E5%BE%A1%2F</url>
    <content type="text"><![CDATA[引用自阿里云https://help.aliyun.com/knowledge_detail/56269.html 什么是暴力破解攻击暴力破解攻击是指攻击者通过系统地组合并尝试所有的可能性以破解用户的用户名、密码等敏感信息。攻击者往往借助自动化脚本工具来发动暴力破解攻击。 攻击行为类型根据暴力破解的穷举方式，其攻击行为可以分为： 字典攻击法。大多攻击者并没有高性能的破解算法和CPU/GPU，为节省时间和提高效率，会利用社会工程学或其它方式建立破译字典，使用字典中已存在的用户名、密码进行猜破。 穷举法。攻击者首先列出密码组合的可能性（如数字、大写字母、小写字母、特殊字符等），然后按密码长度从1位、2位….构成不同的账号和密码对，然后逐个猜试。该方法需要高性能的破解算法和CPU/GPU作支持。 组合式攻击法。使用字典攻击和穷举法的组合攻击方式。 理论上，只要拥有性能足够强的计算机和足够长的时间，大多密码均可以被破解出来。 攻击业务类型 针对Windows操作系统的远程桌面管理协议（RDP）、Linux操作系统的管理协议（SSH）的暴力破解攻击 针对具有登录认证机制的软件服务（如Mysql、SQLserver、FTP、Web前后端登录接口等应用服务）的暴力破解攻击 对于防御者而言，给攻击者留得时间越长，其组合出正确的用户名和密码的可能性就越大。因此，时间在检测暴力破解攻击时很重要。 暴力破解攻击有什么危害通过自动化工具发起的暴力破解攻击可以获取用户账号和密码。 如何防御暴力破解攻击 制定密码复杂度策略，并进行服务加固。密码的长度要大于 8 位，且最好大于 20 位；密码应由数字、大小写字母和特殊符号混合组成；密码的最长有效期为 90 天。 配置好网络访问控制。严格限制将高危服务管理端口直接发布到互联网；建议您使用 VPN 和堡垒机的方式集中管理和审计。 提高内部全员安全意识，禁止借用或共享使用账号。]]></content>
      <categories>
        <category>Linux</category>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch服务安全加固]]></title>
    <url>%2FElasticsearch%E6%9C%8D%E5%8A%A1%E5%AE%89%E5%85%A8%E5%8A%A0%E5%9B%BA%2F</url>
    <content type="text"><![CDATA[引用自阿里云https://help.aliyun.com/knowledge_detail/49913.html&gt; Elasticsearch 是一个基于 Lucene 的搜索服务，它提供了 RESTful web 接口的分布式、多用户全文搜索引擎 。Elasticsearch 是用 Java 开发的，并作为 Apache 许可条款下的开放源码发布，是第二大最流行的企业搜索引擎。 Elasticsearch 应用于云计算中，具有实时搜索、稳定、可靠、快速、安装使用方便等优势；但也存在一些安全隐患：默认安装完成后，Elasticsearch 可以使用 9200 端口通告 web 的方式访问查看数据信息。 漏洞详情Elasticsearch 中存在以下高危漏洞。 类型 CVE 受影响版本 描述 远程命令执行 CVE-2014-3120 - Elasticsearch 的脚本执行 (scripting) 功能，可以很方便地对查询出来的数据进行再加工处理。但是，其使用的 MVEL 脚本引擎没有做过任何防护（或者沙盒包装），可以直接执行任意代码。 远程代码执行 - 1.3.0-1.3.7，1.4.0-1.4 Elasticsearch 使用 Groovy 作为脚本语言，虽然加入了沙盒进行控制，危险的代码会被拦截。但是由于沙盒限制不严格，仅通过黑白名单来判断，导致攻击者可以绕过沙盒，执行远程代码。 未授权访问 - - Elasticsearch 在安装了 River 机制之后可以同步多种数据库数据（包括关系型的MySQL、MongoDB 等）。如果 http://localhost:9200/cat/indices中 indices 包含了 _river，则代表 Elasticsearch 已安装 River 机制。而通过泄露的 http://localhost:9200/_rvier/_search URL 地址，攻击者可以获取到敏感信息。 漏洞成因与危害由于 Elasticsearch 的 HTTP 连接没有提供任何的权限控制措施，一旦部署在公共网络就容易有数据泄露的风险。 安全加固方案使用最新的 Elasticsearch 版本通过正规渠道（如 Elastic 官网）下载 Elasticsearch 的最新版本。 下载完成后，将下载文件的 sha1 值和下载时官网页面提供的 sha1 值进行对比，避免下载过程中被恶意攻击者拦截破坏文件，甚至注入恶意代码。 不要随便安装第三方的插件，插件有可能引入安全漏洞甚至本身自带后门，需谨慎使用。 关注 Elastic 网站，及时更新 Elasticsearch 至最新版本。Elasticsearch 每次版本发布都会优化和改进一部分功能，尤其是安全漏洞的补丁。同时，仔细阅读 Elasticsearch 的版本更新记录。 注意：更新升级前，建议您先进行快照备份，及本地测试。 （推荐）网络访问控制Elasticsearch 默认端口是 9200。 不要把 Elasticsearch 的 9200 端口服务发布到互联网上。 使用 阿里云安全组防火墙 或本地操作系统防火墙对访问源 IP 进行隔离控制。 绑定访问源 IP进入 config 目录，修改 elasticsearch.yml 配置文件中以下参数： 123456network.bind_host: 192.168.0.1# 设置绑定的 IP 地址，可以是 IPv4 或 IPv6 地址，默认为 0.0.0.0。network.publish_host: 192.168.0.1# 设置其它节点和该节点交互的 IP 地址，如果不设置它会自动判断，值必须是个真实的 IP 地址。network.host: 192.168.0.1# 同时设置上述两个参数：bind_host 和 publish_host。 修改默认端口进入 config 目录，修改 elasticsearch.yml 配置文件中以下参数： 123456ransport.tcp.port: 9300# 设置节点间交互的 TCP 端口，默认是 9300。transport.tcp.compress: true# 设置是否压缩 TCP 传输时的数据，默认为 false，即不压缩。http.port: 9200# 设置对外服务的 HTTP 端口，默认为 9200。 关闭 HTTP 访问进入 config 目录，修改 elasticsearch.yml 配置文件中以下参数： 12http.enabled: false# 是否使用 HTTP 协议对外提供服务，默认为 true，即开启。 使用 Shield 安全插件Shield 是 Elastic 公司为 Elasticsearch 开发的一个安全插件。在安装此插件后，Shield 会拦截所有对 Elasticsearch 的请求，并进行认证与加密，保障 Elasticsearch 及相关系统的安全性。Shield 是商业插件，需要 Elasticsearch 的商业许可。第一次安装许可的时候，会提供 30 天的免费试用权限。30 天后，Shield 将会屏蔽 clusterhealth, cluster stats, index stats 等 API，其余功能不受影响。 用户认证使用 Shield 可以定义一系列已知的用户，并用其认证用户请求。这些用户存在于抽象的“域”中。一个“域”可以是下面几种类型： LDAP 服务 ActiveDirectory 服务 本地 esusers 配置文件（类似 /etc/passwd) 权限控制Shield 的权限控制包含下面几种元素： 被保护的资源 SecuredResource：权限所应用到的对象，比如某个 index，cluster 等。 特权 Priviliege：角色对对象可以执行的一种或多种操作，比如 read，write 等。还可以是 indicies:/data/read/perlocate 等对某种对象特有的操作。 许可 Permissions：对被保护的资源拥有的一个或多个特权，如 read on the&quot;products&quot; index。 角色 Role：一组许可的集成，具有独立的名称。 用户 Users：用户实体，可以被赋予多种角色，他们可以对被保护的资源执行相应角色所拥有的各种特权。 安装 Shield执行安装步骤前，请确保满足以下安装环境条件： 您安装了 Java7 或更新版本。 您将 Elasticsearch 1.5.0+ 解压安装到了本机上。如果您使用 APT 或 YUM 安装，默认的安装目录可能在 /usr/share/elasticsearch。 参照以下步骤完成安装： 进入 Elasticsearch 安装目录： 1cd /usr/share/elasticsearch 安装 Elasticsearch 许可插件： 1bin/plugin -i elasticsearch/license/latest 安装 Shield 插件： 1bin/plugin -i elasticsearch/shield/latest 将 Shield 配置文件移动或链接至 /etc/elasticsearch/shield 目录中： 1ln -s /usr/share/elasticsearch/config/shield /etc/elasticsearch/shield 说明：Elasticsearch 服务在启动时会在 /etc/elasticsearch/shield 目录下寻找 Shield 配置文件，而这些配置文件在安装 Shield 时会出现在 /usr/share/elasticsearch/config/shield 中，因此需要将配置文件移动或链接至该目录。 重启 Elasticsearch 服务： 1service elasticsearch restart 新建一个 Elasticsearch 管理员账户，填写新密码： 1bin/shield/esusersuseradd es_admin -r admin 直接使用 RESTFUL API 访问 Elasticsearch 的请求都会被拒绝： 1curl -XGET&apos;http://localhost:9200/&apos; 需要在请求中添加用户名和密码： 1curl -u es_admin -XGET &apos;http://localhost:9200/&apos; 更多信息，请参考： Shield 官方安装指南 Shield 官方使用配置指南 修改默认的 Elasticsearch 集群名称Elasticsearch 默认的集群名称是 elasticsearch，请在您的生产环境中将其修改成其他名称。确保在不同的环境和不同的集群下使用不同的名称；并且在监控集群节点时，如果有未知节点加入，一定要及时预警。 不要以 root 身份运行 Elasticsearch不要以 root 身份来运行 Elasticsearch，不要和其他服务共用相同的用户，并把用户的权限最小化。 应用示例： 1sudo -u es-user ES_JAVA_OPTS=&quot;-Xms1024m -Xmx1024m&quot;/opt/elasticsearch/bin/elasticsearc 正确设置 Elasticsearch 的数据目录请确保为 Elasticsearch 的目录分配了合理的读写权限，避免使用共享文件系统。确保只有 Elasticsearch 的启动用户才有权访问目录。日志目录也需要正确配置，避免泄露敏感信息。 定期对 Elasticsearch 进行备份使用 Elasticsearch 提供的备份还原机制，定期对 Elasticsearch 的数据进行快照备份。 禁用批量删除索引Elasticsearch 支持使用全部（_all）和通配符（*）来批量删除索引。在生产环境，该操作存在一定风险，你可以通过设置 action.destructive_requires_name: true 参数来禁用它。 启用日志记录功能Elasticsearch 的 config 文件夹里面有两个配置文件： elasticsearch.yml：基本配置文件。 logging.yml：日志配置文件。由于 Elasticsearch 使用 log4j 来记录日志的，logging.yml 中的设置请按普通 log4j 配置文件进行设置。 启用日志功能需要修改 elasticsearch.yml 配置文件： 1path.logs: /path/to/logs# 设置日志文件的存储路径，默认是 Elasticsearch 根目录下的 logs 文件夹]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux操作系统加固]]></title>
    <url>%2FLinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8A%A0%E5%9B%BA%2F</url>
    <content type="text"><![CDATA[引自阿里云https://help.aliyun.com/knowledge_detail/49809.html&gt; 本帮助手册旨在指导系统管理人员或安全检查人员进行Linux操作系统的安全合规性检查和加固。 1. 账号和口令1.1 禁用或删除无用账号减少系统无用账号，降低安全风险。 操作步骤 使用命令 userdel &lt;用户名&gt; 删除不必要的账号。 使用命令 passwd -l &lt;用户名&gt; 锁定不必要的账号。 使用命令 passwd -u &lt;用户名&gt; 解锁必要的账号。 1.2 检查特殊账号检查是否存在空口令和root权限的账号。 操作步骤 查看空口令和root权限账号，确认是否存在异常账号： 使用命令 awk -F: &#39;($2==&quot;&quot;)&#39; /etc/shadow 查看空口令账号。 使用命令 awk -F: &#39;($3==0)&#39; /etc/passwd 查看UID为零的账号。 加固空口令账号： 使用命令 passwd &lt;用户名&gt; 为空口令账号设定密码。 确认UID为零的账号只有root账号。 1.3 添加口令策略加强口令的复杂度等，降低被猜解的可能性。 操作步骤 使用命令 1vi /etc/login.defs 修改配置文件。 PASS_MAX_DAYS 90 #新建用户的密码最长使用天数 PASS_MIN_DAYS 0 #新建用户的密码最短使用天数 PASS_WARN_AGE 7 #新建用户的密码到期提前提醒天数 使用chage命令修改用户设置。例如，chage -m 0 -M 30 -E 2000-01-01 -W 7 &lt;用户名&gt;表示将此用户的密码最长使用天数设为30，最短使用天数设为0，密码2000年1月1日过期，过期前七天警告用户。 设置连续输错三次密码，账号锁定五分钟。使用命令 vi /etc/pam.d/common-auth修改配置文件，在配置文件中添加 auth required pam_tally.so onerr=fail deny=3 unlock_time=300。 1.4 限制用户su限制能su到root的用户。 操作步骤 使用命令 vi /etc/pam.d/su修改配置文件，在配置文件中添加行。例如，只允许test组用户su到root，则添加 auth required pam_wheel.so group=test。 1.4 禁止root用户直接登录限制root用户直接登录。 操作步骤 创建普通权限账号并配置密码,防止无法远程登录; 使用命令 vi /etc/ssh/sshd_config修改配置文件将PermitRootLogin的值改成no，并保存，然后使用service sshd restart重启服务。 2. 服务2.1 关闭不必要的服务关闭不必要的服务（如普通服务和xinetd服务），降低风险。 操作步骤 使用命令systemctl disable &lt;服务名&gt;设置服务在开机时不自动启动。 说明： 对于部分老版本的Linux操作系统（如CentOS 6），可以使用命令chkconfig --level &lt;init级别&gt; &lt;服务名&gt; off设置服务在指定init级别下开机时不自动启动。 2.2 SSH服务安全对SSH服务进行安全加固，防止暴力破解成功。 操作步骤 使用命令 vim /etc/ssh/sshd_config 编辑配置文件。 不允许root账号直接登录系统。设置 PermitRootLogin 的值为 no。 修改SSH使用的协议版本。设置 Protocol 的版本为 2。 修改允许密码错误次数（默认6次）。设置 MaxAuthTries 的值为 3。 配置文件修改完成后，重启sshd服务生效。 3. 文件系统3.1 设置umask值设置默认的umask值，增强安全性。 操作步骤 使用命令 vi /etc/profile 修改配置文件，添加行 umask 027， 即新创建的文件属主拥有读写执行权限，同组用户拥有读和执行权限，其他用户无权限。 3.2 设置登录超时设置系统登录后，连接超时时间，增强安全性。 操作步骤 使用命令 vi /etc/profile 修改配置文件，将以 TMOUT= 开头的行注释，设置为TMOUT=180，即超时时间为三分钟。 4. 日志4.1 syslogd日志启用日志功能，并配置日志记录。 操作步骤 Linux系统默认启用以下类型日志： 系统日志（默认）/var/log/messages cron日志（默认）/var/log/cron 安全日志（默认）/var/log/secure 注意：部分系统可能使用syslog-ng日志，配置文件为：/etc/syslog-ng/syslog-ng.conf。 您可以根据需求配置详细日志。 4.2 记录所有用户的登录和操作日志通过脚本代码实现记录所有用户的登录操作日志，防止出现安全事件后无据可查。 操作步骤 运行 [root@xxx /]# vim /etc/profile打开配置文件。 在配置文件中输入以下内容： 123456789101112131415161718historyUSER=`whoami`USER_IP=`who -u am i 2&gt;/dev/null| awk '&#123;print $NF&#125;'|sed -e 's/[()]//g'`if [ "$USER_IP" = "" ]; thenUSER_IP=`hostname`fiif [ ! -d /var/log/history ]; thenmkdir /var/log/historychmod 777 /var/log/historyfiif [ ! -d /var/log/history/$&#123;LOGNAME&#125; ]; thenmkdir /var/log/history/$&#123;LOGNAME&#125;chmod 300 /var/log/history/$&#123;LOGNAME&#125;fiexport HISTSIZE=4096DT=`date +"%Y%m%d_%H:%M:%S"`export HISTFILE="/var/log/history/$&#123;LOGNAME&#125;/$&#123;USER&#125;@$&#123;USER_IP&#125;_$DT"chmod 600 /var/log/history/$&#123;LOGNAME&#125;/*history* 2&gt;/dev/null 运行 [root@xxx /]# source /etc/profile 加载配置生效。注意： /var/log/history 是记录日志的存放位置，可以自定义。 通过上述步骤，可以在 /var/log/history 目录下以每个用户为名新建一个文件夹，每次用户退出后都会产生以用户名、登录IP、时间的日志文件，包含此用户本次的所有操作（root用户除外）。 同时，建议您使用OSS服务收集存储日志。]]></content>
      <categories>
        <category>Linux</category>
        <category>安全</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-快速添加免密码认证]]></title>
    <url>%2FAnsible-%E5%BF%AB%E9%80%9F%E6%B7%BB%E5%8A%A0%E5%85%8D%E5%AF%86%E7%A0%81%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[生成管理机的私钥和公钥1ssh-keygen -t rsa -b 2048 -P '' -f /root/.ssh/id_rsa 添加主机信息到主机清单中1vim /etc/ansible/hosts 123456789101112#添加分组[test-k8s]172.20.21.249172.20.21.250172.20.21.251172.20.21.252172.20.21.253172.20.21.254172.20.21.255172.20.22.0172.20.22.1172.20.22.2 配置playbook1vim /etc/ansible/ssh-addkey.yml 12345678910---- hosts: pro-k8s gather_facts: no tasks: - name: install ssh key authorized_key: user=root key="&#123;&#123; lookup('file', '/root/.ssh/id_rsa.pub') &#125;&#125;" state=present 运行playbook1ansible-playbook -i /etc/ansible/hosts -k /etc/ansible/ssh-addkey.yml 输入服务器密码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465SSH password:PLAY [pro-k8s] ***************************************************************************************************************************TASK [install ssh key] *******************************************************************************************************************changed: [172.21.5.197]changed: [172.21.5.196]changed: [172.21.5.199]changed: [172.21.5.192]changed: [172.21.5.195]changed: [172.21.5.193]changed: [172.21.2.240]changed: [172.21.5.198]changed: [172.21.2.238]changed: [172.21.5.194]changed: [172.21.2.236]changed: [172.21.2.235]changed: [172.21.2.237]changed: [172.21.2.239]changed: [172.21.2.234]changed: [172.21.0.159]changed: [172.21.0.155]changed: [172.21.2.241]changed: [172.21.0.154]changed: [172.21.0.153]changed: [172.21.0.158]changed: [172.21.0.152]changed: [172.21.0.160]changed: [172.21.0.156]changed: [172.21.0.157]changed: [172.21.2.232]changed: [172.21.2.233]changed: [172.21.0.151]changed: [172.21.5.191]PLAY RECAP *******************************************************************************************************************************172.21.0.151 : ok=1 changed=1 unreachable=0 failed=0172.21.0.152 : ok=1 changed=1 unreachable=0 failed=0172.21.0.153 : ok=1 changed=1 unreachable=0 failed=0172.21.0.154 : ok=1 changed=1 unreachable=0 failed=0172.21.0.155 : ok=1 changed=1 unreachable=0 failed=0172.21.0.156 : ok=1 changed=1 unreachable=0 failed=0172.21.0.157 : ok=1 changed=1 unreachable=0 failed=0172.21.0.158 : ok=1 changed=1 unreachable=0 failed=0172.21.0.159 : ok=1 changed=1 unreachable=0 failed=0172.21.0.160 : ok=1 changed=1 unreachable=0 failed=0172.21.2.232 : ok=1 changed=1 unreachable=0 failed=0172.21.2.233 : ok=1 changed=1 unreachable=0 failed=0172.21.2.234 : ok=1 changed=1 unreachable=0 failed=0172.21.2.235 : ok=1 changed=1 unreachable=0 failed=0172.21.2.236 : ok=1 changed=1 unreachable=0 failed=0172.21.2.237 : ok=1 changed=1 unreachable=0 failed=0172.21.2.238 : ok=1 changed=1 unreachable=0 failed=0172.21.2.239 : ok=1 changed=1 unreachable=0 failed=0172.21.2.240 : ok=1 changed=1 unreachable=0 failed=0172.21.2.241 : ok=1 changed=1 unreachable=0 failed=0172.21.5.191 : ok=1 changed=1 unreachable=0 failed=0172.21.5.192 : ok=1 changed=1 unreachable=0 failed=0172.21.5.193 : ok=1 changed=1 unreachable=0 failed=0172.21.5.194 : ok=1 changed=1 unreachable=0 failed=0172.21.5.195 : ok=1 changed=1 unreachable=0 failed=0172.21.5.196 : ok=1 changed=1 unreachable=0 failed=0172.21.5.197 : ok=1 changed=1 unreachable=0 failed=0172.21.5.198 : ok=1 changed=1 unreachable=0 failed=0172.21.5.199 : ok=1 changed=1 unreachable=0 failed=0]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cookie & Session]]></title>
    <url>%2FCookie-Session%2F</url>
    <content type="text"><![CDATA[https://www.cnblogs.com/liwenzhou/p/8343243.html CookieCookie是什么保存在浏览器端的键值对 为什么要有Cookie因为HTTP请求是无状态的 Cookie的原理服务端可以在返回响应的时候 做手脚在浏览器上写入键值对，就是Cookie，浏览器发送请求的时候会自动携带该网站保存在浏览器中的键值对 Cookie的使用场景 保存登录信息 保存用户的搜索关键词 Django中操作Cookie获取Cookie1234567request.COOKIES['key']request.get_signed_cookie(key, default=RAISE_ERROR, salt='', max_age=None)参数： default: 默认值 salt: 加密盐 max_age: 后台控制过期时间 设置Cookie123456789101112131415rep = HttpResponse(...)rep ＝ render(request, ...)rep.set_cookie(key,value,...)rep.set_signed_cookie(key,value,salt='加密盐', max_age=None, ...)参数： key, 键 value='', 值 max_age=None, 超时时间 expires=None, 超时时间(IE requires expires, so set it if hasn't been already.) path='/', Cookie生效的路径，/ 表示根路径，特殊的：根路径的cookie可以被任何url的页面访问 domain=None, Cookie生效的域名 secure=False, https传输 httponly=False 只能http协议传输，无法被JavaScript获取（不是绝对，底层抓包可以获取到也可以被覆盖） 删除Cookie1234def logout(request): rep = redirect("/login/") rep.delete_cookie("user") # 删除用户浏览器上之前设置的usercookie值 return rep 完整views.py示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546# -*- coding: utf-8 -*-from __future__ import unicode_literalsfrom django.shortcuts import render,redirectfrom django.http import HttpResponse,HttpResponseRedirectfrom django.shortcuts import render# Create your views here.def check_login(func): def a(request,*args,**kwargs): Cookies = request.COOKIES.get("is_login", None) if 'yes' != Cookies: return redirect('/test01/login') else: return func(request,*args,**kwargs) return a@check_logindef index(request): return HttpResponse('index界面')@check_logindef home(request): return HttpResponse('home')def login(request): return render(request,'test01/login.html')@check_logindef logout(request): rep = redirect('/test01/login') rep.delete_cookie('is_login') return repdef check_username(request): if request.method == "POST": username = request.POST.get('username',None) password = request.POST.get('password',None) if username == 'z' and password == 'z': rep = render(request,'test01/home.html',&#123;'username':username&#125;) #rep.set_cookie('is_login','yes') rep.set_signed_cookie('is_login', 'yes', expires=60 * 60 * 24 * 7) else: rep = redirect('/test01/login') else: rep = redirect('/test01/login') return rep SessionCookie虽然在一定程度上解决了“保持状态”的需求，但是由于Cookie本身最大支持4096字节，以及Cookie本身保存在客户端，可能被拦截或窃取，因此就需要有一种新的东西，它能支持更多的字节，并且他保存在服务器，有较高的安全性。这就是Session。 问题来了，基于HTTP协议的无状态特征，服务器根本就不知道访问者是“谁”。那么上述的Cookie就起到桥接的作用。 我们可以给每个客户端的Cookie分配一个唯一的id，这样用户在访问时，通过Cookie，服务器就知道来的人是“谁”。然后我们再根据不同的Cookie的id，在服务器上保存一段时间的私密资料，如“账号密码”等等。 总结而言：Cookie弥补了HTTP无状态的不足，让服务器知道来的人是“谁”；但是Cookie以文本的形式保存在本地，自身安全性较差；所以我们就通过Cookie识别不同的用户，对应的在Session里保存私密的信息以及超过4096字节的文本。另外，上述所说的Cookie和Session其实是共通性的东西，不限于语言和框架。 Django中操作Session1234567891011121314151617181920212223242526272829303132333435363738# 获取、设置、删除Session中数据request.session['k1']request.session.get('k1',None)request.session['k1'] = 123request.session.setdefault('k1',123) # 存在则不设置del request.session['k1']# 所有 键、值、键值对request.session.keys()request.session.values()request.session.items()request.session.iterkeys()request.session.itervalues()request.session.iteritems()# 会话session的keyrequest.session.session_key# 将所有Session失效日期小于当前日期的数据删除request.session.clear_expired()# 检查会话session的key在数据库中是否存在request.session.exists("session_key")# 删除当前会话的所有Session数据request.session.delete() # 删除当前的会话数据并删除会话的Cookie。request.session.flush() 这用于确保前面的会话数据不可以再次被用户的浏览器访问 例如，django.contrib.auth.logout() 函数中就会调用它。# 设置会话Session和Cookie的超时时间request.session.set_expiry(value) * 如果value是个整数，session会在些秒数后失效。 * 如果value是个datatime或timedelta，session就会在这个时间后失效。 * 如果value是0,用户关闭浏览器session就会失效。 * 如果value是None,session会依赖全局session失效策略。 Seesion版验证登录12345678910111213141516171819202122232425262728293031323334353637383940from functools import wrapsdef check_login(func): @wraps(func) def inner(request, *args, **kwargs): next_url = request.get_full_path() if request.session.get("user"): return func(request, *args, **kwargs) else: return redirect("/login/?next=&#123;&#125;".format(next_url)) return innerdef login(request): if request.method == "POST": user = request.POST.get("user") pwd = request.POST.get("pwd") if user == "alex" and pwd == "alex1234": # 设置session request.session["user"] = user # 获取跳到登陆页面之前的URL next_url = request.GET.get("next") # 如果有，就跳转回登陆之前的URL if next_url: return redirect(next_url) # 否则默认跳转到index页面 else: return redirect("/index/") return render(request, "login.html")@check_logindef logout(request): # 删除所有当前请求相关的session request.session.delete() return redirect("/login/")@check_logindef index(request): current_user = request.session.get("user", None) return render(request, "index.html", &#123;"user": current_user&#125;) Django中的Session配置12345678910111213141516171819202122232425261. 数据库SessionSESSION_ENGINE = 'django.contrib.sessions.backends.db' # 引擎（默认）2. 缓存SessionSESSION_ENGINE = 'django.contrib.sessions.backends.cache' # 引擎SESSION_CACHE_ALIAS = 'default' # 使用的缓存别名（默认内存缓存，也可以是memcache），此处别名依赖缓存的设置3. 文件SessionSESSION_ENGINE = 'django.contrib.sessions.backends.file' # 引擎SESSION_FILE_PATH = None # 缓存文件路径，如果为None，则使用tempfile模块获取一个临时地址tempfile.gettempdir() 4. 缓存+数据库SESSION_ENGINE = 'django.contrib.sessions.backends.cached_db' # 引擎5. 加密Cookie SessionSESSION_ENGINE = 'django.contrib.sessions.backends.signed_cookies' # 引擎其他公用设置项：SESSION_COOKIE_NAME ＝ "sessionid" # Session的cookie保存在浏览器上时的key，即：sessionid＝随机字符串（默认）SESSION_COOKIE_PATH ＝ "/" # Session的cookie保存的路径（默认）SESSION_COOKIE_DOMAIN = None # Session的cookie保存的域名（默认）SESSION_COOKIE_SECURE = False # 是否Https传输cookie（默认）SESSION_COOKIE_HTTPONLY = True # 是否Session的cookie只支持http传输（默认）SESSION_COOKIE_AGE = 1209600 # Session的cookie失效日期（2周）（默认）SESSION_EXPIRE_AT_BROWSER_CLOSE = False # 是否关闭浏览器使得Session过期（默认）SESSION_SAVE_EVERY_REQUEST = False # 是否每次请求都保存Session，默认修改之后才保存（默认）]]></content>
      <tags>
        <tag>Cookie</tag>
        <tag>Session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx_配置SSL证书]]></title>
    <url>%2FNginx-%E9%85%8D%E7%BD%AESSL%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[获取证书并上传到Ngx服务器 检查Ngx是否安装–with-http_ssl_module模块 修改nginx配置文件 123456789101112131415161718192021222324252627282930313233server &#123; listen 80; server_name *.zhaohongye.com; #return 301 https://$host$request_uri; return 301 https://zhaohongye.com;&#125;server &#123; listen 443 ssl; server_name zhaohongye.com www.zhaohongye.com; access_log /var/log/nginx/zhy.log main; error_log /var/log/nginx/zhy.error.log; ssl on; #ssl功能开启 ssl_certificate sslfile/2027481_zhaohongye.com.pem; ssl_certificate_key sslfile/2027481_zhaohongye.com.key; location / &#123; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_redirect http:// https://; proxy_pass http://127.0.0.1:4000; client_max_body_size 10M; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; # Required for new HTTP-based CLI proxy_http_version 1.1; proxy_request_buffering off; &#125;&#125; https访问验证]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Archer]]></title>
    <url>%2FArcher-SQL%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B9%B3%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[ARCHER — 自动化SQL操作平台基于inception的自动化SQL操作平台，支持SQL执行、LDAP认证、发邮件、OSC、SQL查询、SQL优化建议、权限管理等功能，支持docker镜像。 GitHub项目地址：https://github.com/jly8866/archer 主要功能 自动审核发起SQL上线，工单提交，由inception自动审核，审核通过后需要由审核人进行人工审核 人工审核inception自动审核通过的工单，由其他研发工程师或研发经理来审核，DBA操作执行SQL为什么要有人工审核？这是遵循运维领域线上操作的流程意识，一个工程师要进行线上数据库SQL更新，最好由另外一个工程师来把关很多时候DBA并不知道SQL的业务含义，所以人工审核最好由其他研发工程师或研发经理来审核. 这是archer的设计理念 回滚数据展示工单内可展示回滚语句，支持一键提交回滚工单 定时执行SQL审核通过的工单可由DBA选择定时执行，执行前可修改执行时间，可随时终止 pt-osc执行支持pt-osc执行进度展示，并且可以点击中止pt-osc进程 MySQL查询库、表、关键字自动补全查询结果集限制、查询结果导出、表结构展示、多结果集展示 MySQL查询权限管理基于inception解析查询语句，查询权限支持限制到表级查询权限申请、审核和管理，支持审核流程配置，多级审核 MySQL查询动态脱敏基于inception解析查询语句，配合脱敏字段配置、脱敏规则(正则表达式)实现敏感数据动态脱敏 慢日志管理基于percona-toolkit的pt_query_digest分析和存储慢日志，并在web端展现 邮件通知可配置邮件提醒，对上线申请、权限申请、审核结果等进行通知对异常登录进行通知 安装安装docker 、git1yum install -y docker git 下载镜像123docker pull hhyo/inceptiondocker pull hhyo/archerdocker pull mysql:5.6.35 创建archer配置文件服务目录定为 /vcg/archer/ 1mkdir /vcg/archer/ 123456789101112131415161718192021222324vim /vcg/archer/inc.cnf[inception]general_log=1general_log_file=inception.logport=6669socket=/tmp/inc.socketcharacter-set-client-handshake=0character-set-server=utf8inception_remote_system_password=rootinception_remote_system_user=wzf1inception_remote_backup_port=3306inception_remote_backup_host=127.0.0.1inception_support_charset=utf8,utf8mb4inception_enable_nullable=0inception_check_primary_key=1inception_check_column_comment=1inception_check_table_comment=1inception_osc_on=OFFinception_osc_bin_dir=/usr/bininception_osc_min_table_size=1inception_osc_chunk_time=0.1inception_enable_blob_type=1inception_check_column_default_value=1 12wget https://github.com/jly8866/archer/blob/master/archer/settings.py修改其中的数据库地址、用户名、密码 启动容器12345docker run --name inception -v /vcg/archer/inc.cnf:/etc/inc.cnf -p 6669:6669 -dti hhyo/inceptiondocker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6.35docker run --name archer -v /vcg/archer/settings.py:/opt/archer/archer/settings.py -e NGINX_PORT=9123 -p 9123:9123 -dti hhyo/archer 创建数据库123mysql -uroot -pCREATE DATABASE IF NOT EXISTS archer_github DEFAULT CHARSET utf8 COLLATE utf8_general_ci; 初始化数据库12345678docker exec -ti archer /bin/bash cd /opt/archer source /opt/venv4archer/bin/activate # 初始化数据库 python3 manage.py makemigrations sql python3 manage.py migrate # 创建管理员账号 python3 manage.py createsuperuser 访问地址： http://xxxx::9123/]]></content>
      <categories>
        <category>Archer</category>
      </categories>
      <tags>
        <tag>Archer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo]]></title>
    <url>%2FHexo-%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[快速、简洁且高效的博客框架官网: https://hexo.io 特点超快速度Node.js 所带来的超快生成速度，让上百个页面在几秒内瞬间完成渲染。 支持 MarkdownHexo 支持 GitHub Flavored Markdown 的所有功能，甚至可以整合 Octopress 的大多数插件。 一键部署只需一条指令即可部署到 GitHub Pages, Heroku 或其他网站。 丰富的插件Hexo 拥有强大的插件系统，安装插件可以让 Hexo 支持 Jade, CoffeeScript。 12345$ npm install hexo-cli -g$ hexo init blog$ cd blog$ npm install$ hexo server 最佳实践命令缩写hexo支持指令缩写，例如：hexo generate和hexo g是等效的。d = deploy 部署g = generate 生成静态页面l = log 启动日记记录，使用覆盖记录格式n = new 新建文章o = output 设置输出路径p = port 重设端口s = server 启动服务器w = watch 监视文件变动 组合命令1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 修改首页博客为预览模式12345vim themes/next/_config.ymlauto_excerpt: enable: false length: 150 将 auto_excerpt的enable参数由false改为true]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes_Nginx-Ingress]]></title>
    <url>%2FKubernetes-Nginx-Ingress%2F</url>
    <content type="text"><![CDATA[For example12345678910111213141516171819202122232425262728293031apiVersion: extensions/v1beta1kind: Ingressmetadata: annotations: nginx.ingress.kubernetes.io/force-ssl-redirect: 'true' #代表其中跳转 nginx.ingress.kubernetes.io/service-weight: '' nginx.ingress.kubernetes.io/ssl-redirect: 'true' creationTimestamp: '2018-12-25T10:29:36Z' generation: 1 name: boss namespace: default resourceVersion: '21429383' selfLink: /apis/extensions/v1beta1/namespaces/default/ingresses/boss uid: fa56e2a0-082f-11e9-80cf-00163e0e2421spec: rules: - host: boss1.vcg.com http: paths: - backend: serviceName: node-vcg-boss servicePort: 80 path: / tls: - hosts: - boss1.vcg.com secretName: vcg-httpsstatus: loadBalancer: ingress: - ip: 39.97.21.16]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
